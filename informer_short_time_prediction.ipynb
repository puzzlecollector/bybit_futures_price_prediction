{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "import random \n",
    "import os \n",
    "import torch \n",
    "from torch import nn  \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from sklearn.model_selection import train_test_split \n",
    "import time \n",
    "import datetime \n",
    "import json\n",
    "import ccxt \n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "\n",
    "We process data such that we predict open, high, low, close, volume at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585130400000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>2.636600e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1585134000000</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>2.857722e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585137600000</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>3.484765e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1585141200000</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>6745.5</td>\n",
       "      <td>6562.0</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>2.957732e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1585144800000</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>6640.0</td>\n",
       "      <td>6516.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>1.705696e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13870</th>\n",
       "      <td>1635062400000</td>\n",
       "      <td>60780.5</td>\n",
       "      <td>60780.5</td>\n",
       "      <td>60502.5</td>\n",
       "      <td>60585.5</td>\n",
       "      <td>7.079455e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13871</th>\n",
       "      <td>1635066000000</td>\n",
       "      <td>60585.5</td>\n",
       "      <td>61333.0</td>\n",
       "      <td>60536.0</td>\n",
       "      <td>60868.0</td>\n",
       "      <td>1.251390e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13872</th>\n",
       "      <td>1635069600000</td>\n",
       "      <td>60868.0</td>\n",
       "      <td>61141.0</td>\n",
       "      <td>60832.0</td>\n",
       "      <td>61026.0</td>\n",
       "      <td>4.401238e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13873</th>\n",
       "      <td>1635073200000</td>\n",
       "      <td>61026.0</td>\n",
       "      <td>61049.5</td>\n",
       "      <td>60202.0</td>\n",
       "      <td>60363.0</td>\n",
       "      <td>1.511519e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13874</th>\n",
       "      <td>1635076800000</td>\n",
       "      <td>60363.0</td>\n",
       "      <td>60900.0</td>\n",
       "      <td>59805.0</td>\n",
       "      <td>60450.0</td>\n",
       "      <td>2.789688e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13875 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0        1        2        3        4             5\n",
       "0      1585130400000   6500.0   6591.5   6500.0   6591.5  2.636600e+01\n",
       "1      1585134000000   6591.5   6628.5   6457.5   6511.5  2.857722e+06\n",
       "2      1585137600000   6511.5   6588.5   6502.0   6583.5  3.484765e+06\n",
       "3      1585141200000   6583.5   6745.5   6562.0   6585.0  2.957732e+06\n",
       "4      1585144800000   6585.0   6640.0   6516.0   6590.0  1.705696e+06\n",
       "...              ...      ...      ...      ...      ...           ...\n",
       "13870  1635062400000  60780.5  60780.5  60502.5  60585.5  7.079455e+07\n",
       "13871  1635066000000  60585.5  61333.0  60536.0  60868.0  1.251390e+08\n",
       "13872  1635069600000  60868.0  61141.0  60832.0  61026.0  4.401238e+07\n",
       "13873  1635073200000  61026.0  61049.5  60202.0  60363.0  1.511519e+08\n",
       "13874  1635076800000  60363.0  60900.0  59805.0  60450.0  2.789688e+08\n",
       "\n",
       "[13875 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('BTC_USDT-1h_bybit.json') as f: \n",
    "    df = json.load(f) \n",
    "    \n",
    "df = pd.DataFrame(df) \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585130400000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>2.636600e+01</td>\n",
       "      <td>2020-03-25 10:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1585134000000</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>2.857722e+06</td>\n",
       "      <td>2020-03-25 11:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585137600000</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>3.484765e+06</td>\n",
       "      <td>2020-03-25 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1585141200000</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>6745.5</td>\n",
       "      <td>6562.0</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>2.957732e+06</td>\n",
       "      <td>2020-03-25 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1585144800000</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>6640.0</td>\n",
       "      <td>6516.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>1.705696e+06</td>\n",
       "      <td>2020-03-25 14:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1       2       3       4             5  \\\n",
       "0  1585130400000  6500.0  6591.5  6500.0  6591.5  2.636600e+01   \n",
       "1  1585134000000  6591.5  6628.5  6457.5  6511.5  2.857722e+06   \n",
       "2  1585137600000  6511.5  6588.5  6502.0  6583.5  3.484765e+06   \n",
       "3  1585141200000  6583.5  6745.5  6562.0  6585.0  2.957732e+06   \n",
       "4  1585144800000  6585.0  6640.0  6516.0  6590.0  1.705696e+06   \n",
       "\n",
       "            timestamp  \n",
       "0 2020-03-25 10:00:00  \n",
       "1 2020-03-25 11:00:00  \n",
       "2 2020-03-25 12:00:00  \n",
       "3 2020-03-25 13:00:00  \n",
       "4 2020-03-25 14:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = df[0].values \n",
    "bybit = ccxt.bybit() \n",
    "timestamp = [] \n",
    "for i in range(len(dates)): \n",
    "    date_string = bybit.iso8601(int(dates[i]))  \n",
    "    date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "    timestamp.append(date_string) \n",
    "    \n",
    "df['timestamp'] = timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['timestamp'].dt.year \n",
    "df['month'] = df['timestamp'].dt.month \n",
    "df['day'] = df['timestamp'].dt.day \n",
    "df['weekday'] = df['timestamp'].dt.weekday \n",
    "df['hour'] = df['timestamp'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585130400000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>2.636600e+01</td>\n",
       "      <td>2020-03-25 10:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1585134000000</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>2.857722e+06</td>\n",
       "      <td>2020-03-25 11:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585137600000</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>3.484765e+06</td>\n",
       "      <td>2020-03-25 12:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1585141200000</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>6745.5</td>\n",
       "      <td>6562.0</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>2.957732e+06</td>\n",
       "      <td>2020-03-25 13:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1585144800000</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>6640.0</td>\n",
       "      <td>6516.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>1.705696e+06</td>\n",
       "      <td>2020-03-25 14:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1       2       3       4             5  \\\n",
       "0  1585130400000  6500.0  6591.5  6500.0  6591.5  2.636600e+01   \n",
       "1  1585134000000  6591.5  6628.5  6457.5  6511.5  2.857722e+06   \n",
       "2  1585137600000  6511.5  6588.5  6502.0  6583.5  3.484765e+06   \n",
       "3  1585141200000  6583.5  6745.5  6562.0  6585.0  2.957732e+06   \n",
       "4  1585144800000  6585.0  6640.0  6516.0  6590.0  1.705696e+06   \n",
       "\n",
       "            timestamp  year  month  day  weekday  hour  \n",
       "0 2020-03-25 10:00:00  2020      3   25        2    10  \n",
       "1 2020-03-25 11:00:00  2020      3   25        2    11  \n",
       "2 2020-03-25 12:00:00  2020      3   25        2    12  \n",
       "3 2020-03-25 13:00:00  2020      3   25        2    13  \n",
       "4 2020-03-25 14:00:00  2020      3   25        2    14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13854/13854 [00:02<00:00, 4669.28it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 20 \n",
    "future_size = 1 \n",
    "enc_inputs = [] \n",
    "dec_inputs = [] \n",
    "targets = [] \n",
    "enc_marks = [] \n",
    "dec_marks = [] \n",
    "\n",
    "for i in tqdm(range(df.shape[0] - window_size - future_size), position=0, leave=True):  \n",
    "    ### get enc_inputs, dec_inputs and targets ### \n",
    "    o = df[1].values[i:i+window_size+future_size] \n",
    "    h = df[2].values[i:i+window_size+future_size] \n",
    "    l = df[3].values[i:i+window_size+future_size] \n",
    "    c = df[4].values[i:i+window_size+future_size] \n",
    "    v = df[5].values[i:i+window_size+future_size] \n",
    "    \n",
    "    o = (o - np.min(o)) / (np.max(o) - np.min(o)) \n",
    "    h = (h - np.min(h)) / (np.max(h) - np.min(h)) \n",
    "    l = (l - np.min(l)) / (np.max(l) - np.min(l)) \n",
    "    c = (c - np.min(c)) / (np.max(c) - np.min(c)) \n",
    "    v = v / np.max(v)  \n",
    "    \n",
    "    o_train = o[:window_size].reshape((-1,1)) \n",
    "    o_target = o[-1].reshape((-1,1)) \n",
    "    h_train = h[:window_size].reshape((-1,1))\n",
    "    h_target = h[-1].reshape((-1,1)) \n",
    "    l_train = l[:window_size].reshape((-1,1)) \n",
    "    l_target = l[-1].reshape((-1,1)) \n",
    "    c_train = c[:window_size].reshape((-1,1)) \n",
    "    c_target = c[-1].reshape((-1,1)) \n",
    "    v_train = v[:window_size].reshape((-1,1)) \n",
    "    v_target = v[-1].reshape((-1,1)) \n",
    "    \n",
    "    x = np.concatenate([o_train,h_train,l_train,c_train,v_train],axis=1) \n",
    "    y = np.concatenate([o_target,h_target,l_target,c_target,v_target],axis=1)\n",
    "    y0 = np.zeros((1,5)) \n",
    "\n",
    "    enc_inputs.append(x) \n",
    "    dec_inputs.append(np.concatenate([x,y0], axis = 0)) \n",
    "    targets.append(y)  \n",
    "    \n",
    "    month = df['month'].values[i:i+window_size+future_size].reshape((-1,1)) \n",
    "    day = df['day'].values[i:i+window_size+future_size].reshape((-1,1))\n",
    "    weekday = df['weekday'].values[i:i+window_size+future_size].reshape((-1,1))\n",
    "    hour = df['hour'].values[i:i+window_size+future_size].reshape((-1,1))\n",
    "        \n",
    "    enc_dates = np.concatenate([month[:-1,:], day[:-1,:], weekday[:-1,:], hour[:-1,:]], axis=1)  \n",
    "    enc_marks.append(enc_dates) \n",
    "    \n",
    "    dec_dates = np.concatenate([month, day, weekday, hour], axis=1) \n",
    "    dec_marks.append(dec_dates)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13854, 20, 5), (13854, 21, 5), (13854, 1, 5), (13854, 20, 4), (13854, 21, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inputs = np.array(enc_inputs)\n",
    "dec_inputs = np.array(dec_inputs)\n",
    "targets = np.array(targets) \n",
    "enc_marks = np.array(enc_marks) \n",
    "dec_marks = np.array(dec_marks)\n",
    "\n",
    "\n",
    "enc_inputs.shape, dec_inputs.shape, targets.shape, enc_marks.shape, dec_marks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, encoder_input, decoder_input, target_input, encoder_marks, decoder_marks): \n",
    "        self.encoder_input = encoder_input \n",
    "        self.decoder_input = decoder_input \n",
    "        self.target_input = target_input \n",
    "        self.encoder_marks = encoder_marks \n",
    "        self.decoder_marks = decoder_marks \n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.encoder_input) \n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        return {\n",
    "            'encoder_input': torch.tensor(self.encoder_input[i], dtype=torch.float32), \n",
    "            'decoder_input': torch.tensor(self.decoder_input[i], dtype=torch.float32), \n",
    "            'target': torch.tensor(self.target_input[i], dtype=torch.float32),  \n",
    "            'encoder_marks': torch.tensor(self.encoder_marks[i], dtype=torch.float32), \n",
    "            'decoder_marks': torch.tensor(self.decoder_marks[i], dtype=torch.float32) \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12468, 20, 5),\n",
       " (1386, 20, 5),\n",
       " (12468, 21, 5),\n",
       " (1386, 21, 5),\n",
       " (12468, 1, 5),\n",
       " (1386, 1, 5),\n",
       " (12468, 20, 4),\n",
       " (1386, 20, 4),\n",
       " (12468, 21, 4),\n",
       " (1386, 21, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_enc_inputs, val_enc_inputs, train_dec_inputs, val_dec_inputs = train_test_split(enc_inputs, \n",
    "                                                                                      dec_inputs, \n",
    "                                                                                      random_state = 888, \n",
    "                                                                                      test_size = 0.1)  \n",
    "\n",
    "train_targets, val_targets, _, _ = train_test_split(targets, \n",
    "                                                    dec_inputs, \n",
    "                                                    random_state = 888, \n",
    "                                                    test_size = 0.1) \n",
    "\n",
    "\n",
    "train_enc_marks, val_enc_marks, _, _ = train_test_split(enc_marks, \n",
    "                                                        dec_inputs, \n",
    "                                                        random_state = 888, \n",
    "                                                        test_size = 0.1)\n",
    "\n",
    "train_dec_marks, val_dec_marks, _, _ = train_test_split(dec_marks, \n",
    "                                                        dec_inputs, \n",
    "                                                        random_state = 888, \n",
    "                                                        test_size = 0.1)\n",
    "\n",
    "\n",
    "train_enc_inputs.shape, val_enc_inputs.shape, train_dec_inputs.shape, val_dec_inputs.shape, train_targets.shape, val_targets.shape, train_enc_marks.shape, val_enc_marks.shape, train_dec_marks.shape, val_dec_marks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "\n",
    "train_dataset = CustomDataset(train_enc_inputs, \n",
    "                              train_dec_inputs, \n",
    "                              train_targets, \n",
    "                              train_enc_marks,\n",
    "                              train_dec_marks)\n",
    "\n",
    "val_dataset = CustomDataset(val_enc_inputs, \n",
    "                            val_dec_inputs, \n",
    "                            val_targets, \n",
    "                            val_enc_marks,\n",
    "                            val_dec_marks) \n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True) \n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'Informer2020' in sys.path: \n",
    "    sys.path += [\"Informer2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InformerStack(\n",
       "  (enc_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(5, 512, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TemporalEmbedding(\n",
       "      (hour_embed): FixedEmbedding(\n",
       "        (emb): Embedding(24, 512)\n",
       "      )\n",
       "      (weekday_embed): FixedEmbedding(\n",
       "        (emb): Embedding(7, 512)\n",
       "      )\n",
       "      (day_embed): FixedEmbedding(\n",
       "        (emb): Embedding(32, 512)\n",
       "      )\n",
       "      (month_embed): FixedEmbedding(\n",
       "        (emb): Embedding(13, 512)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (dec_embedding): DataEmbedding(\n",
       "    (value_embedding): TokenEmbedding(\n",
       "      (tokenConv): Conv1d(5, 512, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
       "    )\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (temporal_embedding): TemporalEmbedding(\n",
       "      (hour_embed): FixedEmbedding(\n",
       "        (emb): Embedding(24, 512)\n",
       "      )\n",
       "      (weekday_embed): FixedEmbedding(\n",
       "        (emb): Embedding(7, 512)\n",
       "      )\n",
       "      (day_embed): FixedEmbedding(\n",
       "        (emb): Embedding(32, 512)\n",
       "      )\n",
       "      (month_embed): FixedEmbedding(\n",
       "        (emb): Embedding(13, 512)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (encoder): EncoderStack(\n",
       "    (encoders): ModuleList(\n",
       "      (0): Encoder(\n",
       "        (attn_layers): ModuleList(\n",
       "          (0): EncoderLayer(\n",
       "            (attention): AttentionLayer(\n",
       "              (inner_attention): ProbAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): EncoderLayer(\n",
       "            (attention): AttentionLayer(\n",
       "              (inner_attention): ProbAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (2): EncoderLayer(\n",
       "            (attention): AttentionLayer(\n",
       "              (inner_attention): ProbAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): ConvLayer(\n",
       "            (downConv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ELU(alpha=1.0)\n",
       "            (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "          (1): ConvLayer(\n",
       "            (downConv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ELU(alpha=1.0)\n",
       "            (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Encoder(\n",
       "        (attn_layers): ModuleList(\n",
       "          (0): EncoderLayer(\n",
       "            (attention): AttentionLayer(\n",
       "              (inner_attention): ProbAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): EncoderLayer(\n",
       "            (attention): AttentionLayer(\n",
       "              (inner_attention): ProbAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): ConvLayer(\n",
       "            (downConv): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
       "            (norm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ELU(alpha=1.0)\n",
       "            (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Encoder(\n",
       "        (attn_layers): ModuleList(\n",
       "          (0): EncoderLayer(\n",
       "            (attention): AttentionLayer(\n",
       "              (inner_attention): ProbAttention(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (conv_layers): ModuleList()\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): ProbAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): FullAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attention): AttentionLayer(\n",
       "          (inner_attention): ProbAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attention): AttentionLayer(\n",
       "          (inner_attention): FullAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (query_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (conv1): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection): Linear(in_features=512, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Informer2020.models.model import Informer, InformerStack \n",
    "\n",
    "model = InformerStack(enc_in = 5, # encoder input size \n",
    "                      dec_in = 5, # decoder input size \n",
    "                      c_out = 5, # output size  \n",
    "                      seq_len = window_size, # encoder sequence length \n",
    "                      label_len = window_size, # starter token length \n",
    "                      out_len = future_size, # output sequence length \n",
    "                      attn = 'prob') # use probsparse attention \n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4) \n",
    "criterion = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    # ë°˜ì˜¬ë¦¼\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ssìœ¼ë¡œ í˜•íƒœ ë³€ê²½\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.19750359952449797\n",
      "  Batch    20  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.14759226180613041\n",
      "  Batch    30  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.1250657598177592\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.11138679319992661\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.09914748154580594\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.09198454711586238\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.08674550301262311\n",
      "  Batch    80  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0822557876817882\n",
      "  Batch    90  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.07848952615426646\n",
      "  Batch   100  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.07433762829750776\n",
      "  Batch   110  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.07146811090748419\n",
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.06890354511948923\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.06613551037242779\n",
      "  Batch   140  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0641935813373753\n",
      "  Batch   150  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.06210440548757712\n",
      "  Batch   160  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.06027724015293643\n",
      "  Batch   170  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.05862346775829792\n",
      "  Batch   180  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.05710962650676568\n",
      "  Batch   190  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.055530774426695545\n",
      "  Batch   200  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.05429843229241669\n",
      "  Batch   210  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.05310728225324835\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.05196616881611672\n",
      "  Batch   230  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.05084329887252787\n",
      "  Batch   240  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.04973757584424068\n",
      "  Batch   250  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.04895085859298706\n",
      "  Batch   260  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.04817123415235144\n",
      "  Batch   270  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.04751122184787635\n",
      "  Batch   280  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.046626069589651056\n",
      "  Batch   290  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.045961185217160604\n",
      "  Batch   300  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.045499433670192956\n",
      "  Batch   310  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.044957687597601645\n",
      "  Batch   320  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.044308054668363184\n",
      "  Batch   330  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.043840965453648205\n",
      "  Batch   340  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.04325395477661753\n",
      "  Batch   350  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.04276473828724452\n",
      "  Batch   360  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.04224940879632615\n",
      "  Batch   370  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.04191050782950746\n",
      "  Batch   380  of    390.    Elapsed: 0:00:44.\n",
      "  current average loss = 0.04152176868121483\n",
      "\n",
      "  Average training loss: 0.041142878249192084\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.024874569255519997\n",
      "  Validation epoch took: 0:00:23\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 2 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.022529716975986956\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.026217682100832463\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.024689680027465025\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.02375795617699623\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.023921000640839338\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.024018362490460278\n",
      "  Batch    70  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.024603944098842995\n",
      "  Batch    80  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.02491772953653708\n",
      "  Batch    90  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.025465835661937792\n",
      "  Batch   100  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0252758424077183\n",
      "  Batch   110  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.02568954634903507\n",
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.025225167465396225\n",
      "  Batch   130  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.024933438955877837\n",
      "  Batch   140  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.024943762864651425\n",
      "  Batch   150  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.02492210555821657\n",
      "  Batch   160  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.024782791128382088\n",
      "  Batch   170  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.02462872736265554\n",
      "  Batch   180  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0247560596300496\n",
      "  Batch   190  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.024725133121797912\n",
      "  Batch   200  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.024495457196608186\n",
      "  Batch   210  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.024230799367207855\n",
      "  Batch   220  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.02410188268616118\n",
      "  Batch   230  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.023939894390818867\n",
      "  Batch   240  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.023923851960959534\n",
      "  Batch   250  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.023902450136840343\n",
      "  Batch   260  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.023946860919778164\n",
      "  Batch   270  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.023956039127100398\n",
      "  Batch   280  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.023796253890863487\n",
      "  Batch   290  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.023806766966550513\n",
      "  Batch   300  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.023754882669697205\n",
      "  Batch   310  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.023707152533555223\n",
      "  Batch   320  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.023608287420938723\n",
      "  Batch   330  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.023766549716167377\n",
      "  Batch   340  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.02372234656530268\n",
      "  Batch   350  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.023617405675883805\n",
      "  Batch   360  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.02360457208318015\n",
      "  Batch   370  of    390.    Elapsed: 0:00:44.\n",
      "  current average loss = 0.02353169446609713\n",
      "  Batch   380  of    390.    Elapsed: 0:00:45.\n",
      "  current average loss = 0.02342208060190866\n",
      "\n",
      "  Average training loss: 0.023340576559973833\n",
      "  Training epoch took: 0:00:46\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.03988087274642153\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.026411957386881114\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.02472767443396151\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.023506852487723034\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.022968844580464064\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.02320882199332118\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.02293657584426304\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.022456924244761468\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.021821534924674778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.021347228520446352\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.020952873509377242\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.020910264754837208\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.02061233331914991\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.02078791971390064\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.02071778207485165\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.020549284319082897\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.020464512764010578\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.02045847678776173\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.020438716891739102\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.020514968973829557\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.020359027134254574\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.02037198002494517\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.020420624303038825\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.02029496972327647\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.02023307509177054\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.02024753635376692\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.02042732685087965\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.020348955973706864\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.02049245077318379\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.020427068525218757\n",
      "  Batch   300  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.020364373388389746\n",
      "  Batch   310  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.020321842325070213\n",
      "  Batch   320  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.020336265020887367\n",
      "  Batch   330  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.020296082160238062\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.020226358490831712\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.020199800399797303\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.02018624073308375\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.0201245126994075\n",
      "  Batch   380  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.020081963799403687\n",
      "\n",
      "  Average training loss: 0.019996848757354878\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01901212967508896\n",
      "  Validation epoch took: 0:00:01\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 4 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.018237929977476596\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.018979576462879778\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.018539895707120498\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.018632604787126184\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.018621832448989153\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.018583356635645032\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.018832328928900615\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.01858670721994713\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.018606914579868315\n",
      "  Batch   100  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.018477803897112607\n",
      "  Batch   110  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.018417925260622393\n",
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.01842579886627694\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.018495984010111828\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.018344496010935733\n",
      "  Batch   150  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.018607753856728474\n",
      "  Batch   160  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.01842830831883475\n",
      "  Batch   170  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.01843190770048429\n",
      "  Batch   180  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.018468506592843267\n",
      "  Batch   190  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.018471936004138306\n",
      "  Batch   200  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0184844427369535\n",
      "  Batch   210  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.01850939660022656\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.018530595755543222\n",
      "  Batch   230  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.018695100198459366\n",
      "  Batch   240  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.018730602751020342\n",
      "  Batch   250  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.018592941202223302\n",
      "  Batch   260  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.018686258205427575\n",
      "  Batch   270  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.01856142771602781\n",
      "  Batch   280  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.018799011761854802\n",
      "  Batch   290  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.018798257590367875\n",
      "  Batch   300  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.018725842920442423\n",
      "  Batch   310  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.018727896858247058\n",
      "  Batch   320  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.018640432361280546\n",
      "  Batch   330  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.01858428299257701\n",
      "  Batch   340  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0185849000891561\n",
      "  Batch   350  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0185760072139757\n",
      "  Batch   360  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.01849402137255917\n",
      "  Batch   370  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.018508758499110874\n",
      "  Batch   380  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.018473933918989802\n",
      "\n",
      "  Average training loss: 0.018459556884586045\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.018359381684356114\n",
      "  Validation epoch took: 0:00:01\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 5 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.018999568559229373\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01800201218575239\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.018140344694256783\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01898105216678232\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.018849126398563384\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.018769148426751297\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.018633824946092708\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.01863121778005734\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.018844444822106097\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.019064290039241313\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0189890873872421\n",
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.018679208176520964\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.01849150898364874\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.018228900811768003\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.018063673706104358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.018102742469636723\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.01806023398085552\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.01793889740171532\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.01790568567812443\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.01783025567419827\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.01789565482398584\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.017915241606533527\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.01781096244635789\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.017666511573285484\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.0177568713221699\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0177440108713479\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.017787763153858206\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.017715192215317595\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.017646375290471417\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.01773413682822138\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.017826791523745465\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.017790816571505275\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.017741053180317535\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0176648827502504\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.017607713872566818\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.01761663022528713\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.017534867124128585\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.017523565654348778\n",
      "\n",
      "  Average training loss: 0.017432365097248784\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01712007992054251\n",
      "  Validation epoch took: 0:00:01\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 6 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.016094458661973475\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.017171540996059775\n",
      "  Batch    30  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.017149510762343802\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.018298815726302563\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01798363821581006\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.017622864060103893\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.017582806386053564\n",
      "  Batch    80  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.017522487335372715\n",
      "  Batch    90  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.01763954714147581\n",
      "  Batch   100  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.017535585528239608\n",
      "  Batch   110  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.01739996952766722\n",
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.017351929765815535\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.017402393284898537\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.017143550109384315\n",
      "  Batch   150  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.016990889130781093\n",
      "  Batch   160  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.01687021052930504\n",
      "  Batch   170  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.016632251112776643\n",
      "  Batch   180  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.016708078794181347\n",
      "  Batch   190  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.016827430370214738\n",
      "  Batch   200  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.016765788192860783\n",
      "  Batch   210  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.016780902569492658\n",
      "  Batch   220  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.01670020909302614\n",
      "  Batch   230  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.016717990714570752\n",
      "  Batch   240  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.01662330673619484\n",
      "  Batch   250  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.01676229941099882\n",
      "  Batch   260  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.016780261197485602\n",
      "  Batch   270  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.01676035404412283\n",
      "  Batch   280  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.016849058856522398\n",
      "  Batch   290  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.016838172110247202\n",
      "  Batch   300  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.016788572917381922\n",
      "  Batch   310  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.016833246496295737\n",
      "  Batch   320  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.016838064076728186\n",
      "  Batch   330  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.016814743253317745\n",
      "  Batch   340  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.016833323040319717\n",
      "  Batch   350  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.01678362136972802\n",
      "  Batch   360  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.01681553881822361\n",
      "  Batch   370  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.016876638288030755\n",
      "  Batch   380  of    390.    Elapsed: 0:00:44.\n",
      "  current average loss = 0.016921167249644275\n",
      "\n",
      "  Average training loss: 0.016946004495884362\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015526286167600616\n",
      "  Validation epoch took: 0:00:01\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 7 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.02141519747674465\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.019189512962475418\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.018715840950608253\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01846101237460971\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0189458847977221\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.018510964621479314\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.018000209610909222\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.01781452897703275\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.017671035716517104\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.01735506536439061\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.01708569894121452\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.017170647151457767\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.017016016204769793\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.016959704239187495\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.01697879658391078\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.016878793435171246\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.016818663817556465\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.01687901840131316\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.017090564328981074\n",
      "  Batch   200  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.017178352810442447\n",
      "  Batch   210  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.017000081532058262\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.016867984700101344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.016862869197907655\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.016732582403346897\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.016623030927032233\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.016473162707944328\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.016416000598972594\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.016321265747371527\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.016291114973739303\n",
      "  Batch   300  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.016234052336464324\n",
      "  Batch   310  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.016241097735661653\n",
      "  Batch   320  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.016283362478134222\n",
      "  Batch   330  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.016257949150872954\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.016235119030427406\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.016218342344675746\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.016141572749863067\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.016140641551464795\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.016149413691049344\n",
      "\n",
      "  Average training loss: 0.01611488976348669\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.018408146940849045\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 8 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.015932734683156015\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.015853139339014888\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01579347892353932\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01603932254947722\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015731221865862607\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.015361631366734704\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.015371919915612256\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.015392329188762233\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.015146910818293691\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.01525550386402756\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.015310006389733065\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.015106017185219874\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.014955726086806792\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.015031006845778653\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.015070982246349255\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.01512812526198104\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.015220375720630674\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.015270873645527495\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.01516404219559933\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.015042533494997769\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.015067955875946653\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.015107576292939484\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.015033816560374006\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.014892634072263414\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.014840377977117895\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.014932469631401966\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.014948550799723577\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.015048179487764303\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.015091828094666889\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.015182549613527954\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.01532979796099807\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.015305066046130378\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.015367687421596863\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.015451109838014579\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.015461024371907115\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.015447365317959339\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.015463596092839095\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.015496897853077634\n",
      "\n",
      "  Average training loss: 0.015510140625664439\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016120554180815816\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 9 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01700948951765895\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.015326059842482209\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.015483778125296036\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.014756539929658174\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.014618655294179916\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.014549687256415684\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.014452145448220627\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.014258250361308455\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.014201558060530159\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.014078794000670313\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.014014083176681942\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.014073307831616451\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.014074117521970318\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.014117834088392556\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.014167383688812455\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.014271173006272874\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.01423950763693189\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.014203002632388637\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.014326453392737006\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.014277551050763577\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.014400829669709007\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.014488681915893474\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.014582302265436105\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.01456257725561348\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.01463482023589313\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.01464938648367444\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.014664534488003011\n",
      "  Batch   280  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.014614972237697137\n",
      "  Batch   290  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.014619903972950475\n",
      "  Batch   300  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.01467843298179408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   310  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.014694079059746958\n",
      "  Batch   320  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.01464934230898507\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.014672803607853975\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0146889626788085\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.014687942157366445\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.014637714514457103\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.014591169851907605\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.014595113996122228\n",
      "\n",
      "  Average training loss: 0.014588398837412779\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016087150455198505\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 10 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01586530189961195\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.014758564764633775\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.014626062971850236\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.013746755314059556\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.013862674087285996\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.013977044463778536\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.014075198523434146\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.01425328102777712\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.014161533101772268\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.013968484667129815\n",
      "  Batch   110  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.013982471819459037\n",
      "  Batch   120  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.014109960314817727\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.014142205881384703\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.014257136253373964\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.014191915169358254\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.014174126635771245\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.014091773314730209\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.01412052343496018\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.014150663999546516\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.014151350746396929\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.014161607696275625\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.014197312809780918\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.014175573029838826\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.014091572167429452\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.014080867873504758\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.014075103905410148\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.01406382004454456\n",
      "  Batch   280  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.014101755783693598\n",
      "  Batch   290  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.014097375408264584\n",
      "  Batch   300  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.014098127094718317\n",
      "  Batch   310  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.014025960634312322\n",
      "  Batch   320  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.014100817035068759\n",
      "  Batch   330  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.014044579136834451\n",
      "  Batch   340  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.01405996918979594\n",
      "  Batch   350  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.014042755377345851\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.014100512894543095\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.014127369138185639\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.01413600023860406\n",
      "\n",
      "  Average training loss: 0.014156494338590748\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.0214005998251113\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 11 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.013561053294688463\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.013260637177154422\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01330386254315575\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.013349921116605401\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01306519253179431\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.01304572099664559\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.01313153148096587\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.0130569048167672\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.012978060631495383\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.013061335678212344\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.012935878095132384\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.012887059970914076\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.01294962651669406\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.01310424334702215\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.013342359385763605\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.013354412888293154\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.01347252852831255\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0135311998711485\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.013440734302428993\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.01343374484917149\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.013466817018620314\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.013467691699042916\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.013455880174170369\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.01345363495638594\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.013427693467587232\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.013385661018009368\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.013385233279593565\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.013377069821581244\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.013435119316624156\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.013477526726201177\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.013450544886291027\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.013433389837155118\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.01342673675072464\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.013504022636505611\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.01351242092038904\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.01358542844083988\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.013592007564934524\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.013568348305201844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.013667100796905848\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.018171033695001493\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 12 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.012988769123330713\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.013368172268383206\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.013176718990628918\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01327137666521594\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.013349534710869193\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01329200560382257\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.013354856913377131\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.013358001940650866\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.013159066976772413\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.013063383279368282\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.013226338035681032\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.013312085042707622\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.013259072293742345\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.013207768063460077\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.013193379708876213\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.013162558327894657\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.013129566615337835\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.013191543410842617\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.013361144551125012\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.01342608590144664\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.01336268319171809\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.013363344167274508\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.013320643294845586\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.013217252246492232\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.013134035432711244\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.013114551624927957\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.013109562064831456\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.013065299952203142\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.013069151555477032\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.013090351386927069\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.013139415104242583\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.013216572660894599\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.013197756207294084\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.013201840502648231\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.013187366517792854\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.013209658663254232\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.013225019281428005\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.013208673123613393\n",
      "\n",
      "  Average training loss: 0.013257367124494452\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015191344036297365\n",
      "  Validation epoch took: 0:00:01\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 13 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.014097856357693672\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.013109844736754894\n",
      "  Batch    30  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.012683891225606203\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.012609835644252599\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.013036004789173604\n",
      "  Batch    60  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.01319736718821029\n",
      "  Batch    70  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.013133804087660142\n",
      "  Batch    80  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0129045135458\n",
      "  Batch    90  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.012835154268476699\n",
      "  Batch   100  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.012699500927701592\n",
      "  Batch   110  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.012708541378378868\n",
      "  Batch   120  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.012570575810968876\n",
      "  Batch   130  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.012354935874016239\n",
      "  Batch   140  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.012350084522872099\n",
      "  Batch   150  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.012367703036094706\n",
      "  Batch   160  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.012308857499738224\n",
      "  Batch   170  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.01229005849591511\n",
      "  Batch   180  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.012371552158664497\n",
      "  Batch   190  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.012408895699895527\n",
      "  Batch   200  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.012466707297135145\n",
      "  Batch   210  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.01250944202544079\n",
      "  Batch   220  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.012556458101607859\n",
      "  Batch   230  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.012565150482418097\n",
      "  Batch   240  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.012581040157238021\n",
      "  Batch   250  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.012696177186444401\n",
      "  Batch   260  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.012706779271292571\n",
      "  Batch   270  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.012741530729733684\n",
      "  Batch   280  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.012759142255942737\n",
      "  Batch   290  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.012767112871696209\n",
      "  Batch   300  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.012878595252210896\n",
      "  Batch   310  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.012887273701809107\n",
      "  Batch   320  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.012900982366409153\n",
      "  Batch   330  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.01295979694096428\n",
      "  Batch   340  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.012959338157602094\n",
      "  Batch   350  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.012924949480220676\n",
      "  Batch   360  of    390.    Elapsed: 0:00:44.\n",
      "  current average loss = 0.012908496421813551\n",
      "  Batch   370  of    390.    Elapsed: 0:00:45.\n",
      "  current average loss = 0.01288844581466873\n",
      "  Batch   380  of    390.    Elapsed: 0:00:46.\n",
      "  current average loss = 0.012840685680949766\n",
      "\n",
      "  Average training loss: 0.012831235019108041\n",
      "  Training epoch took: 0:00:48\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017867312279783866\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 14 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.00975292744114995\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.00983748238068074\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.010433069818342725\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011048680904787033\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011382485264912248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011441365256905556\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.011668261300240243\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.011581153684528545\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.011646017458082901\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.011693680589087308\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.011750366348265246\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.011771513184066862\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.011764465795400051\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.011827128187620214\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.011880192384123802\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.011893325485289097\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.012038549085092895\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.01210028267879453\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.012046291818842291\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.012121721340809017\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.012104320111462757\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.01215637417467819\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.012232321806494957\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.012168552598450334\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.012241601634770631\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.012337626172946049\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.012406630448445127\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.012461928391296949\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.012494638061215138\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.012570073734968901\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.012574379185154553\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.012621475974447094\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.012648639421571385\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.012674414402093081\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.012743432769285782\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.012796015183751782\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.012758243116676001\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.01272517383637789\n",
      "\n",
      "  Average training loss: 0.012740927036756125\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015106732618402351\n",
      "  Validation epoch took: 0:00:01\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 15 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011161433905363083\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.010841936012730003\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011395941876495877\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011284440371673555\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011012015081942082\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.011173842024678986\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.011211619433015584\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.011313662910833956\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.011433798473121391\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.01138446523807943\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.011570078341967681\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.01162207688127334\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.01170304362805417\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.011631948387782488\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.01181854156156381\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.011832145176595078\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.011743973921436597\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.011786754530233642\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.011845581436921892\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.011830317450221627\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.011802063778131491\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.011931326695379208\n",
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.011931951479662372\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.011982105010732387\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.01210743790306151\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.01206030505351149\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.012035165226983804\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.011993938691115804\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.012011878748006861\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.012029821189741293\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.012061779008757684\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.012091451307060196\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.012085782177746297\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.012085878413499278\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.012159072868525982\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.012194956580383911\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.012168628396466374\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.012229565149908396\n",
      "\n",
      "  Average training loss: 0.012209446124063852\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015909011031247\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 16 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01202605376020074\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.011769171012565494\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01146871286133925\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011383399181067944\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01157389910891652\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011530795794290801\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.011574521474540234\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.01135890330770053\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.011253707954246137\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.011345540187321604\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.011481867032125592\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.011467066706003\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.011476648466375012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0114409513838057\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.011462355044980844\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.01150134087074548\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.011482608822338721\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.01154689725695385\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.011628011168029747\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.011636467669159174\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.011573936508613682\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.011587948629378595\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.011628374378399357\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.011651773876898612\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.011690642731264234\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.011695317445824353\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.01171973589980216\n",
      "  Batch   280  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.011736969119270465\n",
      "  Batch   290  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.011741536479957146\n",
      "  Batch   300  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.01174263123733302\n",
      "  Batch   310  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.01174721865644378\n",
      "  Batch   320  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.011801458994159474\n",
      "  Batch   330  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.011808061063515417\n",
      "  Batch   340  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0118326978155357\n",
      "  Batch   350  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.01180191321431526\n",
      "  Batch   360  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.01176739248007329\n",
      "  Batch   370  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.011778612310268187\n",
      "  Batch   380  of    390.    Elapsed: 0:00:44.\n",
      "  current average loss = 0.011837963751321168\n",
      "\n",
      "  Average training loss: 0.011880364062455602\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016785968634807927\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 17 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.013323691580444575\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01203265185467899\n",
      "  Batch    30  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.012018567711735765\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011603022925555706\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0119846929050982\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.01169170233576248\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.011599092438284839\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.011713496246375143\n",
      "  Batch    90  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.011421023883546393\n",
      "  Batch   100  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.011287656486965716\n",
      "  Batch   110  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.011115138825367797\n",
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.011050260874132316\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.011066890271523824\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.011012016496221935\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.010946358783791462\n",
      "  Batch   160  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.010879807727178559\n",
      "  Batch   170  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.010849683203131837\n",
      "  Batch   180  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.010848954317366911\n",
      "  Batch   190  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.010905422035016512\n",
      "  Batch   200  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.01085393962683156\n",
      "  Batch   210  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.010826079458707855\n",
      "  Batch   220  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.010813513169573113\n",
      "  Batch   230  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.010838954308596643\n",
      "  Batch   240  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.010884272347902879\n",
      "  Batch   250  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.010874664597213268\n",
      "  Batch   260  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.010879439953714608\n",
      "  Batch   270  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.010893260511673159\n",
      "  Batch   280  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.010892626470220941\n",
      "  Batch   290  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.010878777320914227\n",
      "  Batch   300  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.010894134930955868\n",
      "  Batch   310  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.010942008347821332\n",
      "  Batch   320  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.01094322896678932\n",
      "  Batch   330  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.010989095829427243\n",
      "  Batch   340  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.010986694641520871\n",
      "  Batch   350  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.010978275803583008\n",
      "  Batch   360  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.01098216313144399\n",
      "  Batch   370  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.011028780312453574\n",
      "  Batch   380  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.011022426844819596\n",
      "\n",
      "  Average training loss: 0.011036277373727315\n",
      "  Training epoch took: 0:00:45\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015228697437454353\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 18 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011248517874628305\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.011879756301641464\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011268642374003927\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011474456160794944\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011388316052034497\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.011327827884815633\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.011258390871807933\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.011149469891097396\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.010875397946478592\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.010806411211378873\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.01072710550136187\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.010560706343191366\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.010617278140181532\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.010567159192370517\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.01048495776640872\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.010532037317170761\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.010509268364266437\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.010468949204207295\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.010502736378265055\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.010543563165701925\n",
      "  Batch   210  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.01051933925731906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.010541731290603902\n",
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.01056605052486386\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.010582717822398991\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.010556511400267482\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.010565840556787756\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.010535709937620494\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.010523251630365849\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.010573953518579746\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.010540595102744799\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.010503816754827576\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.010573538116295822\n",
      "  Batch   330  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.01060661792783349\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.01061266310622587\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.01065012992758836\n",
      "  Batch   360  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.010711431531752977\n",
      "  Batch   370  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.010696329790595415\n",
      "  Batch   380  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.010730113461613655\n",
      "\n",
      "  Average training loss: 0.010768882621031923\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01554229850245809\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 19 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.009568671463057399\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.009592069359496237\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.009952423892294367\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0098977483343333\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.010109828617423773\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.009965019153120617\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.01006910502910614\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.010031572123989464\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.010023966116002864\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.010006153956055641\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.009990521998737347\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.01001324598910287\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.009944366495339916\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.009944106279207127\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.009999145111069084\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.010038392076967283\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.010009614035815876\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.009895793069154024\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.009914358928309459\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.010018345448188484\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.010047622943030937\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.010078003928488628\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.010074539138409106\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.010017567626588668\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.009989115642383695\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.009979714059199278\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.009995108339245672\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.010010737551575792\n",
      "  Batch   290  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.010046941767735728\n",
      "  Batch   300  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.010098040575782457\n",
      "  Batch   310  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.010128149597515021\n",
      "  Batch   320  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.010186485364101827\n",
      "  Batch   330  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.010186854882560896\n",
      "  Batch   340  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.01020666031194303\n",
      "  Batch   350  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.01021246772525566\n",
      "  Batch   360  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.01021548528612281\n",
      "  Batch   370  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.01022204031186128\n",
      "  Batch   380  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.010219898191280663\n",
      "\n",
      "  Average training loss: 0.010253717390915905\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014904952798546716\n",
      "  Validation epoch took: 0:00:01\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 20 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011161434976384044\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.010372823965735734\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.010261030386512477\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.010161454684566706\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.009896523403003812\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.00988126666440318\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.009813983046582767\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.009874116233550011\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.009747850087781748\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.009719034102745354\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.009688979662446813\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.009783652607196321\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.009848663490265608\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.009763909011547054\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.009774090250333151\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.009792980854399502\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.009758813166990876\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.009725210665621691\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.009720643685738507\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.009729158042464405\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.009726743859105876\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.009701504209078848\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.009773629136464517\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.009817380194241802\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.009779157945886255\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.009851845337722737\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.009864668939607564\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.009900029055175504\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.009942375561864725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.009996189877080421\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.010036545871726928\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.010078569324105047\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.010063167421542334\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.01006980552611982\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.010098168694281153\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.010103082338658472\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.010125222769440025\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.010118687547449219\n",
      "\n",
      "  Average training loss: 0.0101552189172556\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015112805995158851\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 21 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.00845503518357873\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.008965724101290106\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.00901344888843596\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.009102427412290125\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009041136987507343\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.009160144844402869\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.009365839065451707\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.009312832105206326\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.00936438327965637\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.009213766092434525\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.009235259179364552\n",
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.009261721492900202\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.009212638595356391\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.009156449461754944\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.009143576246375839\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.00917659150727559\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.00921021190143245\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.009187627066340711\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.009194738601677513\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.009268177777994425\n",
      "  Batch   210  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.00925966775310891\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.00918571119704707\n",
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.00915809186661373\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.009131737406520794\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.00918031474761665\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0091649364393491\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.009177248152317824\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.009225083544983395\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.009260328772381463\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.009278193009085953\n",
      "  Batch   310  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.00928028491626103\n",
      "  Batch   320  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.00929110438155476\n",
      "  Batch   330  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.009337148219911438\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.009366371620939496\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.00937481565534004\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.009447556650007351\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.009469101530172535\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.00945623202960154\n",
      "\n",
      "  Average training loss: 0.009474931100908763\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015633843225342305\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 22 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.010038853622972965\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.009386663534678518\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.009937795189519724\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.009533757029566913\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009522593170404435\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.009627314594884714\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.009635870125410811\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.009509460569825023\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.009374789267571435\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.009302133959718049\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.00926500669341873\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.00935303825729837\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.00932573926850007\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.00926444462966174\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.009165737961108486\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.009117283081286587\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.009040648249142311\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.009003059563433958\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.008999899723321984\n",
      "  Batch   200  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.008987857706379145\n",
      "  Batch   210  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.008953124559706165\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.008937098214995455\n",
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.008916416499034865\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.008934872775959472\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.008947532182559371\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.008958802571018727\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.008965611937283366\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.008976844365575484\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.008956268616020679\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.008953631035983562\n",
      "  Batch   310  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.008981665187785702\n",
      "  Batch   320  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.008941961186064874\n",
      "  Batch   330  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.008915559508640206\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.008908880532116574\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.008881828753011568\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.008878246602964483\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.008885514469364204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.008928712715982999\n",
      "\n",
      "  Average training loss: 0.008955269591070902\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01931377330964262\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 23 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.008568960661068558\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.00788633746560663\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.007993026760717233\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.007861376868095248\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.007611745176836849\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0078029501639927425\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.007735161603029285\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.00771722873323597\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.007796860041303767\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.00783831042703241\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.00785359361801635\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.007837438156517844\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.007894909220676009\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.007932663775448288\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.008002890888601542\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.008013609345653094\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.008010090660194263\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.008017474208544526\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.008053313742244715\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.00807938099373132\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.008118925574013875\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.008132513872855766\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.008156744366430718\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.008161174626244853\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.008182613814249635\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.008175317498926932\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.008165621105581522\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.008148808280072575\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.008169698903080204\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.00817389927028368\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.008174632955342532\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.008193070013658144\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.008176147606167378\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.008170507457929061\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.008178868522601468\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.00817799642811426\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.00818229743430542\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.008213275773940902\n",
      "\n",
      "  Average training loss: 0.008263921133505228\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015214169927110726\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 24 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.008996512461453676\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.008502128417603672\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.008394237949202459\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.008112309651914984\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.007663226593285799\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.007558834692463279\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.007620107641975795\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.007642879930790514\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.007891196824817193\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.007915486050769686\n",
      "  Batch   110  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.007831102732399647\n",
      "  Batch   120  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.007895538622202972\n",
      "  Batch   130  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.00786575350122383\n",
      "  Batch   140  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.007816673213216876\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.007814430569609006\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0077589864522451535\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0077541405472027905\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.007739844424132672\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.007645645568539437\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0076099217799492185\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.007580596099918087\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.007629717171022838\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.007617193152723105\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.007606762199429795\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.007573889771476388\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.007612796002425827\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.007658370122037552\n",
      "  Batch   280  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.007682802090753935\n",
      "  Batch   290  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.007692126348486234\n",
      "  Batch   300  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.007697416466350357\n",
      "  Batch   310  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.007690653727660256\n",
      "  Batch   320  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0077112000595661815\n",
      "  Batch   330  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.007703292780471119\n",
      "  Batch   340  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.007699014901128762\n",
      "  Batch   350  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0077076560218951535\n",
      "  Batch   360  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.007690695223088065\n",
      "  Batch   370  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.007688024080031225\n",
      "  Batch   380  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.007696130830108335\n",
      "\n",
      "  Average training loss: 0.007694385181634854\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015348411207510666\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 25 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.00662266225554049\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.005998764745891094\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.006146163175192972\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.006427895760862157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.00670274252537638\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.006782578812756886\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.006720196495630912\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.006848233478376642\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.006908056755653686\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.00704293695744127\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.007160906434397806\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.007391092363589754\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.007395009968716365\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0074090410323281375\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.007388974536831181\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0074132397276116535\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.007462580660905908\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0074199552026887735\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.007448260662587065\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.007441842702683062\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.007392697178182148\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.007435383262451399\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.007425947274769778\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.007407140995686253\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.007392910271883011\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.007417552024484254\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.007468378019553644\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.007449811663744705\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.007449913154966358\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.007450390590044359\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.007431676002940343\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.00746219877328258\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.007471415641802278\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.007511306926608086\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.007565163105194058\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0076039575622417034\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.007593706605100148\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.007613865401301729\n",
      "\n",
      "  Average training loss: 0.0076036049542614285\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016013676565225152\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 26 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.007451062882319092\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.006977071077562869\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.006970885628834367\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.007201206148602068\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.007020078022032976\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.006895490805618465\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0069597550335207155\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.006942660518689081\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.006952790771093634\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.00696940622292459\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.00697950221682814\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.006965187525687118\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.007026729374550856\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.00703353096531438\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.007078486584747831\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0070678418123861775\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.007084325687302386\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.007067390226034654\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.007050303867282836\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.007083234149031341\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.007160693910416393\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.007181058999743651\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.007188872124432869\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.007189919524050007\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.0071669296082109216\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.007194489591683333\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.007195716449576947\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0072410366930333635\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.007238928422909872\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.007297808102642496\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.007326474679153292\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.007337994285626337\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.007354701152353576\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.007368725043831064\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.007407569076333727\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.007428022135152585\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0074445593435115915\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.00748441411966556\n",
      "\n",
      "  Average training loss: 0.00749140859891971\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016621208432215182\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 27 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.006799223367124796\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.007432000292465091\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.007372102094814181\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.00721955670742318\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.007108915848657488\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.007076749725577732\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.0070438883999096496\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.006927191175054759\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.006800009227461285\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.006761318729259074\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.006695575931702148\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.006695958937052637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.006701721193698737\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0066571704211777875\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.006682629802574714\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.006733795747277327\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.006771042666343205\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.006790942864285575\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.006827213308822952\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.006817939563188702\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.006807853294802563\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.006794864709743045\n",
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.006789769963158862\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.006846599913357446\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.006882348049432039\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0069141838162277754\n",
      "  Batch   270  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.006947706805335151\n",
      "  Batch   280  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.006926187667496768\n",
      "  Batch   290  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.006931595792512185\n",
      "  Batch   300  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.0069051972380839285\n",
      "  Batch   310  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.006900298961197897\n",
      "  Batch   320  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.006942939967120765\n",
      "  Batch   330  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.006972385215516569\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.006951035515350454\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.006950162701042635\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.006927567929960787\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.006949927553383482\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.0069647195798001795\n",
      "\n",
      "  Average training loss: 0.006942334049978317\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01706972081129524\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 28 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.005491087818518281\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.005325316463131458\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.005785631644539535\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.005871750990627334\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.005922408825717866\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.00595954816089943\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.006012958524349544\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.005935386542114429\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0059722279224337805\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.005988182832952589\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.006030852269296619\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.006075640071261054\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.00609118055122403\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.006086830319171506\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.00608944064937532\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.006099882561829873\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.006075177219805911\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.006068857566505256\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.006106476812917543\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.006102212254190818\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.006077621911563689\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.006172660872636532\n",
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.006172569554663547\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.0062334252550499515\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.006295110548846424\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.006322673664320834\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.006304652011884308\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.006282992362477151\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.006297392596426452\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0063236838819769525\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.006316502056565256\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.006363650790444808\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.006376866342245855\n",
      "  Batch   340  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.006379107683760059\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.006384139297130917\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.006392144191259932\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.006390248631076837\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.006373406996288778\n",
      "\n",
      "  Average training loss: 0.0063803439894213505\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015305890511213378\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 29 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.005622302833944559\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.005783111951313913\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.00562861223394672\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.0053740526549518105\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.005342858005315065\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.005335061787627637\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.005370825299594019\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.00564683718548622\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.005786922566282253\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.005896803939249367\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.005929104799658738\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.006003729558627432\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.006009904325653154\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.006017876245147948\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.006074740102825066\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.006076711589412298\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.006169972600250998\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.006221263380979912\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0062374328520443095\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.006214112091111019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.006238434997032441\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.006227016018237918\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.006253325093902\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.006268972008062216\n",
      "  Batch   250  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.0062762743262574075\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.006281660847330036\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.006266933009545836\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.006286093116172457\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.006289971468103086\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0062993419162618615\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.006295035394179004\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.006298906823940342\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.006302344719314891\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.006304047409417655\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.006300491757823953\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.006277857462151183\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0062815386852299844\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.006312369909382573\n",
      "\n",
      "  Average training loss: 0.006343580419436479\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017087811053815214\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 30 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0063331760466098785\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.006387463770806789\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.006140048087884983\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.00586507537518628\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.005825771945528686\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.005759994154019902\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.005734606206949268\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.005667066181194969\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.005645799367792076\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.005618692915886641\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.005626149505207485\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0056513943321382\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.005669118338622726\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.005667537996279341\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.005660168215011557\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0056403688329737635\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.00558630130116773\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.005551603774074465\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.0055664433742334185\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.00555243442999199\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.005531278968833032\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.005548578570596874\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.0055677073865966955\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.005558025190839544\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.005547730664722621\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.005538498335338843\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.005544886899318684\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.005561695686109098\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.005570024262375102\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.005581237042788416\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0056132271562913255\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.005623431360436371\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.005639273171651769\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.005631407361258479\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0056439196052295824\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.005680079483944509\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.005730324909342705\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.005794784176702562\n",
      "\n",
      "  Average training loss: 0.005839460603415202\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016695235051553358\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 31 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0058815846219658855\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.005731897591613233\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.005971874894263844\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.005951626948080957\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.005993029619567096\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.005927388610628744\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.005892455032361406\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.005809468677034602\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.005797552348424991\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0057735953992232684\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.00574705429290506\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.005763870190518597\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.005752084420349163\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.005736700606731964\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.005739882367973527\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0057047050155233595\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.005686128140865441\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.005692059397956149\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.00568283880251999\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0056750089570414275\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.005716668396434259\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.005781835255170749\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.005783029336927701\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.005766282354791959\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.005750242419540882\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.005747035383963241\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.005743803742721125\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.005757284926117531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.005783497174431024\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.005801346485192577\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.00583064143560947\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.005809975694137393\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.005830773158760911\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.005863010489573593\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.005881129439388002\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.005886756518803951\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.005887634095710677\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.005874595364653751\n",
      "\n",
      "  Average training loss: 0.005864012997167615\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017602732532065023\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 32 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.004591839388012886\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.00489578596316278\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0047931098534415165\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.005021054134704173\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.005089210006408393\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.00526537325931713\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.005276598628344281\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.005212719144765288\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.005164443980902433\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.005190768023021519\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.005240201992406087\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.005242707615252584\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.005198372012147537\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0052128282425526\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.005218870065485438\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.005200630429317244\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.005191626835285741\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0051735560125153925\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.005162592033708566\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.005167508414015174\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.00516614497395321\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.005196088648782196\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.005223109798870333\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.005225051506810511\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.005214638057164848\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.005203879568188523\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.005208800562346975\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.00520286318496801\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.005192426076672714\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.005202986009729405\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.005249391874719051\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.00528779421292711\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.005285679060740001\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.005289341406622792\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.005288192688354424\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.005293373752566468\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.005271985583837974\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.005274918599446353\n",
      "\n",
      "  Average training loss: 0.005274874368945184\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017497186168012293\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 33 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.00463742830324918\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.004597819596529007\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.004537345034380754\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.004640785732772201\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.004631897513754666\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.00467574146653836\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.004613864082576973\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.004595195286674425\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.004598684314017495\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.004671237152069807\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.004705038484693928\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.004690681252395734\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.004748770392213303\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.004790772635689272\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.004858686888280014\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.004872554770554416\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0049207118312444755\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.004934997173647085\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.00492569400904406\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.00492828412912786\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.00492204021041592\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.004920526190703226\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.004931366987242971\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0049521510993751384\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.004951535425148904\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.004956385971476825\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.004972797781401486\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.004979634230923174\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.00497431568801403\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.004996668832997481\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.005013030518837754\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.005037194914621068\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.005062480020393251\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.005068002602167647\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.005077552124192672\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0050850815391944105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.005105906838828043\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.005106315706660481\n",
      "\n",
      "  Average training loss: 0.005139219843281003\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016764995705505662\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 34 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.005109448218718171\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.005639097874518484\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.005481874058023095\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.00522413911530748\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.005111314319074154\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.004916719192018111\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.004782146521444832\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.004773809615289793\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.004718938731174502\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.004713040955830365\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.004651737719012255\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0045990660088136796\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.004542579788428086\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.004512982279993594\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.004497894559366008\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0045195663915365\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.004546588471652392\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.004573007710536735\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.004551727557554841\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.004562976801535115\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.004598348226309532\n",
      "  Batch   220  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0045968583499250764\n",
      "  Batch   230  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.004628544097320865\n",
      "  Batch   240  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.004636480987149601\n",
      "  Batch   250  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.004640697563998401\n",
      "  Batch   260  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.004654228025510048\n",
      "  Batch   270  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.004674375249521324\n",
      "  Batch   280  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.004697163795520152\n",
      "  Batch   290  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.004724450274531183\n",
      "  Batch   300  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.004731971657990167\n",
      "  Batch   310  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.004732082386110579\n",
      "  Batch   320  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.004731420887401328\n",
      "  Batch   330  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.004747984885717883\n",
      "  Batch   340  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.0047514931517927085\n",
      "  Batch   350  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.004746811453119984\n",
      "  Batch   360  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.004752344034043037\n",
      "  Batch   370  of    390.    Elapsed: 0:00:45.\n",
      "  current average loss = 0.0047490590434471095\n",
      "  Batch   380  of    390.    Elapsed: 0:00:46.\n",
      "  current average loss = 0.004742994465816178\n",
      "\n",
      "  Average training loss: 0.004747421226392572\n",
      "  Training epoch took: 0:00:47\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016540599933994763\n",
      "  Validation epoch took: 0:00:02\n",
      "\n",
      "======== Epoch 35 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0042184835998341445\n",
      "  Batch    20  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0042723258258774875\n",
      "  Batch    30  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.004282276464315752\n",
      "  Batch    40  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.004225114540895447\n",
      "  Batch    50  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.004155715513043105\n",
      "  Batch    60  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.004154894912304977\n",
      "  Batch    70  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.004137815445262406\n",
      "  Batch    80  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.004090369603363797\n",
      "  Batch    90  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.004094506166357961\n",
      "  Batch   100  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.004053677606862038\n",
      "  Batch   110  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.004049455884590067\n",
      "  Batch   120  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.004085429499779517\n",
      "  Batch   130  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.004122579051181674\n",
      "  Batch   140  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.00415173285374684\n",
      "  Batch   150  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.004189443153639634\n",
      "  Batch   160  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.004215398810629267\n",
      "  Batch   170  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.00425585383302806\n",
      "  Batch   180  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0042662936004085675\n",
      "  Batch   190  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.004292683870727686\n",
      "  Batch   200  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.00431216393597424\n",
      "  Batch   210  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0043387126986913025\n",
      "  Batch   220  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.004351980205286633\n",
      "  Batch   230  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.004371025480087037\n",
      "  Batch   240  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.004359376877740336\n",
      "  Batch   250  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.004358403831720353\n",
      "  Batch   260  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.004370940995151893\n",
      "  Batch   270  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.004366242366463498\n",
      "  Batch   280  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.004361307336616197\n",
      "  Batch   290  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.004359393352482082\n",
      "  Batch   300  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.004373537045127402\n",
      "  Batch   310  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.004358674075093961\n",
      "  Batch   320  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.00437028590895352\n",
      "  Batch   330  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.004385240838129186\n",
      "  Batch   340  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.00439766355420408\n",
      "  Batch   350  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.004391089794891221\n",
      "  Batch   360  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.004390004446031525\n",
      "  Batch   370  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.004389496745441008\n",
      "  Batch   380  of    390.    Elapsed: 0:00:43.\n",
      "  current average loss = 0.004398457329769276\n",
      "\n",
      "  Average training loss: 0.004408165620257839\n",
      "  Training epoch took: 0:00:44\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016527945440347223\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 36 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0038080387515947224\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.003919705329462886\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.004054673970676959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.00403960079420358\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.003957222602330148\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.003873789155234893\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0038459236301215632\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.0038742795848520474\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.003857460054051545\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.003877291106618941\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0038796300703490324\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.003894209072071438\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.003878371173945757\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0039027129416354\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0038821106978381673\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0038536920023034328\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0038615633624003213\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0038756146561354397\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.003887763887790865\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0039052761998027564\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0039057268794359906\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.003929345766929063\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.003926472880108201\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.003927079618248778\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.003962544946931303\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.003968796271006935\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.003972904432427\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.003980762712723975\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.00399242601164713\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.0040209020938103395\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.004021783585419819\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.004040297214669408\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.004048426257389964\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.004052859621451181\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.004072166330048016\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.004087543752717061\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.004107144068473497\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.004114589823630491\n",
      "\n",
      "  Average training loss: 0.004142339573576091\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015588249217464843\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 37 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0044786697020754215\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.004515305208042264\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.004320805721605817\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.004191463260212913\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0041586435306817295\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.004110641952138394\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0040645221081961475\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.003979419518145733\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.003959435754869547\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0039180222782306375\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.003907665051519871\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0038906989716148625\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.003895445250404569\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0038839412254414387\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.003868811164672176\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0038960707417572847\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0039049292051726403\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.0039377367046351235\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.003948211666245601\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.003945101265562698\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.00392967197556226\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.003951850184239447\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.003987532907732479\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.004022967143100686\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.004075435621663928\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.004115325884105494\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.004127224683071728\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.004164078988833353\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.004213039567372922\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.004252812964841724\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.004329679416672837\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.004369907989894273\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0044172231693554555\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.004457435997285168\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.004486698805620627\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.004506966469731802\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.004537294000210996\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.0045339034251427575\n",
      "\n",
      "  Average training loss: 0.0045318495762797124\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01669020645997741\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 38 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.004674559738487005\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.00479206774616614\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.004630687312843899\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.004713435441954061\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.004720815904438496\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.004651385588416209\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.0046218549433563435\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.004645517832250335\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.004723061652233203\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0046713542775250975\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0046684796816076745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   120  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.004645268015641098\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.004641050440617479\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0046522069788937056\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.004654627464090785\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.004708859111997299\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.004825385177836698\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.004896197540478574\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.004937201488370958\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.004958311759401113\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0049803206286880945\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.005042206452609124\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.00507488866518859\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.005079894577890324\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.00515061399154365\n",
      "  Batch   260  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0052120226390588165\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.005217359622905928\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.0052668584136491906\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.005294803683324877\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.005310948792224129\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.005325547266270846\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.005372958227235358\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.00539795088821627\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.005411966412793845\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.005421393278187939\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.005419518433821698\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.005412425093252111\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.005389897867816648\n",
      "\n",
      "  Average training loss: 0.005374360925709017\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016842603154311128\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 39 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.004407807439565659\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.004143530619330704\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.004166145801233748\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.004117976175621152\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.004047664552927017\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.003993474241967002\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.004020879454245525\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.003979104984318837\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.003952058909150461\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.003915544571354985\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0038944081022319467\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.003954857657663524\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.003962397620153542\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.003921737372209983\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.003908648748571674\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0039142542373156175\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.003933029138373539\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.003927438713920613\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.003906642402963419\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0039049372193403543\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0038892346899956467\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0038727809992534193\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.00387313444795006\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0038809887948445974\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0039051419058814645\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.003929178602097986\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.003950990791674013\n",
      "  Batch   280  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0039628070222014295\n",
      "  Batch   290  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0039710910902519166\n",
      "  Batch   300  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.003975649715090792\n",
      "  Batch   310  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.003962286848634962\n",
      "  Batch   320  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.003958425466407789\n",
      "  Batch   330  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.003954242939609244\n",
      "  Batch   340  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.003947069594526992\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.003942885603090482\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.00394404113629005\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.003946442129971409\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.003948235457248398\n",
      "\n",
      "  Average training loss: 0.003947456226421472\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01874197280796414\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 40 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0036884098779410126\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.0034577072598040103\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0033722270901004473\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.003345767268911004\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.003302161991596222\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.00325994788048168\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0032515771487461667\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.00320959406089969\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.0031990997363916703\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.003219282056670636\n",
      "  Batch   110  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0032397595297714524\n",
      "  Batch   120  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0032228690727303427\n",
      "  Batch   130  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0032226085035990063\n",
      "  Batch   140  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.003232761795100357\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0032356132240965963\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0032301894898409955\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.003251966949114028\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.00327697778508688\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.0032915843613935927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.00329212763463147\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.003316908766559902\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0033177867722274227\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.0033223708767605863\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.003332273729999239\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0033310519326478242\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.003326086116095002\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.0033269813922406346\n",
      "  Batch   280  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0033362482932196664\n",
      "  Batch   290  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.003349093460991722\n",
      "  Batch   300  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.0033714144335438806\n",
      "  Batch   310  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.0033698723118211473\n",
      "  Batch   320  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.003379028697236208\n",
      "  Batch   330  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.003383057122118771\n",
      "  Batch   340  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.003384692068485653\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0033899548144212793\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0033824175279328805\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.003381734000946823\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.003394767855857744\n",
      "\n",
      "  Average training loss: 0.003422907049743793\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016191076550802045\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 41 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0037825221195816995\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.003729162493254989\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0035406112127626937\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.003388660296332091\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.003209708291105926\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0031172504920201996\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.00312984221215759\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.0031108247058000416\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.003096356680099335\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0031381470058113336\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0031161068430678412\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.003116453270195052\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.003114940646964197\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.003116906402699117\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.003111616247333586\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.003114680126600433\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0031295007724753197\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0031297774079980124\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.0031342300831487305\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0031266369309742004\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.003150415035807306\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.003162541426718235\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.003178909891689925\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.003189127327641472\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.003197497770190239\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.003204364466588371\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0032107071183552897\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.003224720578041992\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.003225560111379058\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.003249115972624471\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0032694028299902716\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.003269046067725867\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0032958931141448293\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.00330936091075487\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0033250573284125755\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0033351400795961833\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.003341328594959467\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.003352899344539956\n",
      "\n",
      "  Average training loss: 0.0033607262407596675\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016576802982440728\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 42 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.003699873574078083\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.003858909709379077\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.003635251281472544\n",
      "  Batch    40  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0035070593003183603\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.003449720530770719\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0034559642508005103\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.0034991809665890676\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.0034948715590871872\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.00341968372101999\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0033446274604648353\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.003327490126883442\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0033303620002698153\n",
      "  Batch   130  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0032991979199533277\n",
      "  Batch   140  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.003277476554337357\n",
      "  Batch   150  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0032557965737457077\n",
      "  Batch   160  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.00323263492755359\n",
      "  Batch   170  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0032264838666271637\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.003231587960746967\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0032118948495113535\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0032003110204823315\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.003197632022645502\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.0031915826225568625\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0031770349470088663\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.003172564981893326\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.003174226458184421\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.003171914882169893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0031610666774213314\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.0031548819305109127\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.0031520682242538395\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.003170924057873587\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.003175125872686265\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.003171063759509707\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.003168587951751595\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0031670606866314567\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0031755656762314692\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.003189929950490801\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.003198309991559064\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.003206868215439547\n",
      "\n",
      "  Average training loss: 0.0032322475197127994\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015978003195910292\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 43 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0027458623051643373\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.0030431469553150237\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.003066422906704247\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.0030077633680775763\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.003096000347286463\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0031194110750220718\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0031518441092755114\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.003129754133988172\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0030843273633056217\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.003061724188737571\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0030600993957539853\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0030566895691057044\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.0030686075082765178\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.003085336716113878\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.003073744303546846\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0030803692003246396\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0030746538130402125\n",
      "  Batch   180  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.003079984046699893\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0030758949995384013\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0030819428950781005\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0030736664326728455\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.003058333462633362\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0030578406694669116\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.00304773888735023\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.003062848187517375\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.0030710322249573297\n",
      "  Batch   270  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0030732198312223235\n",
      "  Batch   280  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.0030752937363493923\n",
      "  Batch   290  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.0030834617008904702\n",
      "  Batch   300  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0030846447866254797\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.003087513841643569\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.003094585552389617\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0031003496316826026\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.003095787580412648\n",
      "  Batch   350  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0030988548519755047\n",
      "  Batch   360  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.00309794476973669\n",
      "  Batch   370  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.0031034774785685176\n",
      "  Batch   380  of    390.    Elapsed: 0:00:42.\n",
      "  current average loss = 0.0031126339683970926\n",
      "\n",
      "  Average training loss: 0.003129480734694367\n",
      "  Training epoch took: 0:00:43\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017516359528103334\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 44 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0029054399114102126\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.0027730323956348\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.002729846350848675\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.002713398289051838\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.002754040395375341\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.00271975202485919\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.002729108340905181\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.002753717605082784\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.002781856759813511\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0027894228778313846\n",
      "  Batch   110  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0027530987821096048\n",
      "  Batch   120  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.002742391876139057\n",
      "  Batch   130  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0027515901494413043\n",
      "  Batch   140  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.0027330355194862934\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.002733247889361034\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0027579291294387077\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.002762901027659502\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0027662207663524895\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.0027805214778422135\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0027776382194133475\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0027715548978275843\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0027866841828323562\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.002800592394930351\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0028087094023552103\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0028212744942866267\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.0028211203587348932\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.0028297007355528574\n",
      "  Batch   280  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0028506851518094274\n",
      "  Batch   290  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.002866165272907579\n",
      "  Batch   300  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.002878334492367382\n",
      "  Batch   310  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.0028856530113356006\n",
      "  Batch   320  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.002887558781003463\n",
      "  Batch   330  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.0028829218982013337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   340  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.0028970674693803576\n",
      "  Batch   350  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0029077444997216975\n",
      "  Batch   360  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0029103499843687233\n",
      "  Batch   370  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0029159580036444035\n",
      "  Batch   380  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0029239129085142754\n",
      "\n",
      "  Average training loss: 0.002926531967181617\n",
      "  Training epoch took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017070665828544985\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 45 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.002464880351908505\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.0027459614211693406\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.002716044367601474\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.002647010568762198\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0027372784353792666\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0027155456540640444\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.002764407999347895\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.002814042266982142\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.002827664877339784\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.002843029793584719\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.002862717557317493\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0028234082322645313\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.002806079381396278\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.002792844419101519\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.002795283240266144\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.002776265091233654\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0027558155926218366\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.002770110125291265\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.0027698200196027757\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0027655861782841383\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0027546908822841942\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.002756470003144138\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0027784827210859436\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.002792221836959167\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.0027972789970226587\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.002791288756102753\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0027983400655944867\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0027979457335147472\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.0028096065872573648\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.002811041628786673\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0028106630434312167\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.0028138229259639046\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.00281495259171634\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.002822925036033506\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0028284478207517946\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0028302517674294197\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.002833550929318409\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.002832339331507683\n",
      "\n",
      "  Average training loss: 0.002835230387221926\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.019152731401845813\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 46 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.002453463536221534\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.002563397824997082\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0026201629739565154\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.0025639287079684435\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.002552377311512828\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.002560293272836134\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.002626099977974913\n",
      "  Batch    80  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.0026488352814340033\n",
      "  Batch    90  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.0026314385869126355\n",
      "  Batch   100  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0026622640516143293\n",
      "  Batch   110  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0026866628566164187\n",
      "  Batch   120  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0027065160693988824\n",
      "  Batch   130  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.00269299373209763\n",
      "  Batch   140  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.002679522512646924\n",
      "  Batch   150  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.002667440512062361\n",
      "  Batch   160  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0026543687490629964\n",
      "  Batch   170  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0026512951001196224\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0026457523707196944\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.002642770210207489\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.002644223891547881\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.002639796755587061\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0026292962149124252\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.002619329828809461\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.002617058878725705\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0026194753842428324\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.002626539439482328\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.002632379064043225\n",
      "  Batch   280  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.002644220058157641\n",
      "  Batch   290  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0026599402142014226\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.0026726442206806192\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0026948018326243806\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.0027228917821048525\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.0027375526221779484\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.00274150278795894\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0027605141868947873\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0027789115682632353\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0027890502654544604\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0028133506038054627\n",
      "\n",
      "  Average training loss: 0.002828262680962395\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.020978956229307434\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 47 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0030110408319160343\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.0030755859101191164\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0031492309101546806\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.0032033012190368026\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0032860577711835504\n",
      "  Batch    60  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0032543201329341778\n",
      "  Batch    70  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.003255720720959029\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.003268857092189137\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0032825965447247857\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.003262553244130686\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.003240242499900474\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.0032081456554199877\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.003232864164209996\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0032459593602522673\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0032519996096380057\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.003240664931217907\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.003245228040716885\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0032490560558572825\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.003236062266545272\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0032377599430037664\n",
      "  Batch   210  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0032391485209310694\n",
      "  Batch   220  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.003233678931560875\n",
      "  Batch   230  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.003217533923705797\n",
      "  Batch   240  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0032026127509501142\n",
      "  Batch   250  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0031855927142314614\n",
      "  Batch   260  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.003160539311983694\n",
      "  Batch   270  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.003148991433920822\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0031402148559988873\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.0031380643277300587\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.003134323104362314\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.003139653439528399\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.0031319084529968675\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.0031244728999974374\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.003121728135396124\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0031263113164875125\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0031328972180037656\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.003142879972851055\n",
      "  Batch   380  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0031427422896836343\n",
      "\n",
      "  Average training loss: 0.0031354396260725574\n",
      "  Training epoch took: 0:00:41\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016140074807811867\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 48 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0031017408706247806\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.002885740716010332\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.002792979039562245\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.0027306596166454256\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0027011925214901564\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.002742934871154527\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.002732476735088442\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.002706113294698298\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0026704982932036123\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.002631361483363435\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.0026192357223904267\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.002604979321282978\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.0025904811112783276\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0025744109705556186\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0025662301395398875\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.002556206493318314\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.002565696944400449\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0025827461071053727\n",
      "  Batch   190  of    390.    Elapsed: 0:00:20.\n",
      "  current average loss = 0.0026022965878885434\n",
      "  Batch   200  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0025913364376174285\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.0025840421356926008\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.002592363985869187\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.002604187252101205\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.002603799268157066\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.0025988446245901286\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.002595443499740213\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0025913562655828343\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.002599550977798312\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.0026055737667524353\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.002619008688488975\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.002621360558025058\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.002631018543615937\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0026380100982461236\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.002647302480181679\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.002664727244326579\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.002678427965858848\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0026915241721891673\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.002693439753248209\n",
      "\n",
      "  Average training loss: 0.00269180906470865\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.018656075170094318\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 49 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.002373129373881966\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.0023880423745140434\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0023323942247467735\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.002324143145233393\n",
      "  Batch    50  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0022770179575309158\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0023285828453178206\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.002346159449578928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.002384813647950068\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.002405091041388611\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.0024446578044444323\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.002448807468383827\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.002484701425419189\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.002518265684529279\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.0025312111821092134\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0025404594163410364\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0025458191004872786\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0025418242823113412\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0025399894240157057\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.0025450128792343955\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.0025848356122151017\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.002598620971132602\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.002604023199422624\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.0026160179197018884\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0026190770765727694\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.002640765433665365\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.002644092198729945\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.0026526919285835768\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.0026554377221535627\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.00265823918764062\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.002666224338269482\n",
      "  Batch   310  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.002671703889650563\n",
      "  Batch   320  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.002674589116577408\n",
      "  Batch   330  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0026750159636845417\n",
      "  Batch   340  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.0026795440733514944\n",
      "  Batch   350  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.0026725261887934593\n",
      "  Batch   360  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0026643175253411753\n",
      "  Batch   370  of    390.    Elapsed: 0:00:40.\n",
      "  current average loss = 0.0026636381963947536\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.0026694487225828005\n",
      "\n",
      "  Average training loss: 0.002672050138995147\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.018186914882707326\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "======== Epoch 50 / 50 ========\n",
      "Training...\n",
      "  Batch    10  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.002420332620386034\n",
      "  Batch    20  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.002393294940702617\n",
      "  Batch    30  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.002303340033783267\n",
      "  Batch    40  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.002295846203924157\n",
      "  Batch    50  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0022759420587681236\n",
      "  Batch    60  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.0022697218887818356\n",
      "  Batch    70  of    390.    Elapsed: 0:00:08.\n",
      "  current average loss = 0.002259775888108249\n",
      "  Batch    80  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.002224545333592687\n",
      "  Batch    90  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.0022288123482010432\n",
      "  Batch   100  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.002228486882522702\n",
      "  Batch   110  of    390.    Elapsed: 0:00:12.\n",
      "  current average loss = 0.002236866274721582\n",
      "  Batch   120  of    390.    Elapsed: 0:00:13.\n",
      "  current average loss = 0.002221318319789134\n",
      "  Batch   130  of    390.    Elapsed: 0:00:14.\n",
      "  current average loss = 0.002227522354895392\n",
      "  Batch   140  of    390.    Elapsed: 0:00:15.\n",
      "  current average loss = 0.002229222793331636\n",
      "  Batch   150  of    390.    Elapsed: 0:00:16.\n",
      "  current average loss = 0.0022215493147571884\n",
      "  Batch   160  of    390.    Elapsed: 0:00:17.\n",
      "  current average loss = 0.0022161405220685994\n",
      "  Batch   170  of    390.    Elapsed: 0:00:18.\n",
      "  current average loss = 0.0022227347677792695\n",
      "  Batch   180  of    390.    Elapsed: 0:00:19.\n",
      "  current average loss = 0.0022247711513450163\n",
      "  Batch   190  of    390.    Elapsed: 0:00:21.\n",
      "  current average loss = 0.002225640469451288\n",
      "  Batch   200  of    390.    Elapsed: 0:00:22.\n",
      "  current average loss = 0.002227570862160064\n",
      "  Batch   210  of    390.    Elapsed: 0:00:23.\n",
      "  current average loss = 0.002248279599007219\n",
      "  Batch   220  of    390.    Elapsed: 0:00:24.\n",
      "  current average loss = 0.0022648515925869682\n",
      "  Batch   230  of    390.    Elapsed: 0:00:25.\n",
      "  current average loss = 0.002276481825190232\n",
      "  Batch   240  of    390.    Elapsed: 0:00:26.\n",
      "  current average loss = 0.0023040210765126784\n",
      "  Batch   250  of    390.    Elapsed: 0:00:27.\n",
      "  current average loss = 0.002333835571538657\n",
      "  Batch   260  of    390.    Elapsed: 0:00:28.\n",
      "  current average loss = 0.0023634531065069428\n",
      "  Batch   270  of    390.    Elapsed: 0:00:29.\n",
      "  current average loss = 0.002367007010616362\n",
      "  Batch   280  of    390.    Elapsed: 0:00:30.\n",
      "  current average loss = 0.002364776619859705\n",
      "  Batch   290  of    390.    Elapsed: 0:00:31.\n",
      "  current average loss = 0.002378533157953543\n",
      "  Batch   300  of    390.    Elapsed: 0:00:32.\n",
      "  current average loss = 0.002381364912725985\n",
      "  Batch   310  of    390.    Elapsed: 0:00:33.\n",
      "  current average loss = 0.0023813228738764603\n",
      "  Batch   320  of    390.    Elapsed: 0:00:34.\n",
      "  current average loss = 0.0023969271031091923\n",
      "  Batch   330  of    390.    Elapsed: 0:00:35.\n",
      "  current average loss = 0.0024020780675169644\n",
      "  Batch   340  of    390.    Elapsed: 0:00:36.\n",
      "  current average loss = 0.0024101024325800073\n",
      "  Batch   350  of    390.    Elapsed: 0:00:37.\n",
      "  current average loss = 0.002419445785095117\n",
      "  Batch   360  of    390.    Elapsed: 0:00:38.\n",
      "  current average loss = 0.002418450171697057\n",
      "  Batch   370  of    390.    Elapsed: 0:00:39.\n",
      "  current average loss = 0.0024229564373633144\n",
      "  Batch   380  of    390.    Elapsed: 0:00:41.\n",
      "  current average loss = 0.002428589726638931\n",
      "\n",
      "  Average training loss: 0.0024344444325647484\n",
      "  Training epoch took: 0:00:42\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.035121839832175865\n",
      "  Validation epoch took: 0:00:01\n",
      "\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "epochs = 50 \n",
    "model.zero_grad() \n",
    "\n",
    "# for reproducibility \n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "train_losses, val_losses = [], [] \n",
    "\n",
    "for epoch_i in range(0, epochs): \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    t0 = time.time() \n",
    "    total_loss = 0 \n",
    "    model.train() \n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):  \n",
    "        if step % 10 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            print('  current average loss = {}'.format(total_loss / step))\n",
    "            \n",
    "        encoder_input = batch['encoder_input'].to(device) \n",
    "        decoder_input = batch['decoder_input'].to(device) \n",
    "        target = batch['target'].to(device) \n",
    "        enc_marks = batch['encoder_marks'].to(device)  \n",
    "        dec_marks = batch['decoder_marks'].to(device) \n",
    "        \n",
    "        with torch.cuda.amp.autocast(): \n",
    "            output = model(x_enc=encoder_input,\n",
    "                           x_mark_enc=enc_marks, \n",
    "                           x_dec=decoder_input, \n",
    "                           x_mark_dec=dec_marks) \n",
    "            loss = criterion(output, target) \n",
    "            total_loss += loss.item() \n",
    "            loss.backward() \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step() \n",
    "            # gradient initialization \n",
    "            model.zero_grad() \n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)  \n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time() \n",
    "    model.eval() \n",
    "    eval_loss = 0 \n",
    "    for batch in val_dataloader: \n",
    "        encoder_input = batch['encoder_input'].to(device) \n",
    "        decoder_input = batch['decoder_input'].to(device) \n",
    "        target = batch['target'].to(device) \n",
    "        enc_marks = batch['encoder_marks'].to(device)  \n",
    "        dec_marks = batch['decoder_marks'].to(device)   \n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            outputs = model(x_enc=encoder_input,\n",
    "                            x_mark_enc=enc_marks, \n",
    "                            x_dec=decoder_input, \n",
    "                            x_mark_dec=dec_marks) \n",
    "            loss = criterion(outputs, target) \n",
    "            eval_loss += loss.item()  \n",
    "        \n",
    "    avg_val_loss = eval_loss / len(val_dataloader) \n",
    "    val_losses.append(avg_val_loss) \n",
    "    print(\"\")\n",
    "    print(\"  Average validation loss: {}\".format(avg_val_loss))\n",
    "    print(\"  Validation epoch took: {:}\".format(format_time(time.time() - t0))) \n",
    "        \n",
    "    if np.min(val_losses) == val_losses[-1]: \n",
    "        print(\"Saving Best Checkpoint....\")\n",
    "        torch.save(model.state_dict(), \"btc_informer_stack_\" + str(epoch_i + 1) + \"_val_loss_\" + str(val_losses[-1])) \n",
    "\n",
    "        \n",
    "        \n",
    "print(\"\")\n",
    "print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train_loss') \n",
    "plt.plot(val_losses, label='val_loss') \n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('loss(mse)') \n",
    "plt.title('loss_plot') \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635109200000</td>\n",
       "      <td>61186.0</td>\n",
       "      <td>61343.0</td>\n",
       "      <td>60852.0</td>\n",
       "      <td>61009.5</td>\n",
       "      <td>8.998808e+07</td>\n",
       "      <td>2021-10-24 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1635112800000</td>\n",
       "      <td>61009.5</td>\n",
       "      <td>61103.5</td>\n",
       "      <td>60860.0</td>\n",
       "      <td>60957.5</td>\n",
       "      <td>3.615479e+07</td>\n",
       "      <td>2021-10-24 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1635116400000</td>\n",
       "      <td>60957.5</td>\n",
       "      <td>60995.5</td>\n",
       "      <td>60752.0</td>\n",
       "      <td>60901.5</td>\n",
       "      <td>4.064861e+07</td>\n",
       "      <td>2021-10-24 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1635120000000</td>\n",
       "      <td>60901.5</td>\n",
       "      <td>61840.0</td>\n",
       "      <td>60708.5</td>\n",
       "      <td>61827.5</td>\n",
       "      <td>1.381452e+08</td>\n",
       "      <td>2021-10-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1635123600000</td>\n",
       "      <td>61827.5</td>\n",
       "      <td>62145.5</td>\n",
       "      <td>61730.0</td>\n",
       "      <td>61746.0</td>\n",
       "      <td>1.034869e+08</td>\n",
       "      <td>2021-10-25 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1635379200000</td>\n",
       "      <td>58481.5</td>\n",
       "      <td>58917.5</td>\n",
       "      <td>58305.0</td>\n",
       "      <td>58327.0</td>\n",
       "      <td>8.970379e+07</td>\n",
       "      <td>2021-10-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1635382800000</td>\n",
       "      <td>58327.0</td>\n",
       "      <td>59022.0</td>\n",
       "      <td>58144.0</td>\n",
       "      <td>58945.0</td>\n",
       "      <td>1.322635e+08</td>\n",
       "      <td>2021-10-28 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1635386400000</td>\n",
       "      <td>58945.0</td>\n",
       "      <td>58945.0</td>\n",
       "      <td>58720.0</td>\n",
       "      <td>58940.0</td>\n",
       "      <td>2.747237e+07</td>\n",
       "      <td>2021-10-28 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1635390000000</td>\n",
       "      <td>58940.0</td>\n",
       "      <td>59184.0</td>\n",
       "      <td>58739.0</td>\n",
       "      <td>58889.5</td>\n",
       "      <td>5.342441e+07</td>\n",
       "      <td>2021-10-28 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1635393600000</td>\n",
       "      <td>58889.5</td>\n",
       "      <td>59237.0</td>\n",
       "      <td>58872.0</td>\n",
       "      <td>58905.0</td>\n",
       "      <td>4.696608e+07</td>\n",
       "      <td>2021-10-28 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        1        2        3        4             5  \\\n",
       "0   1635109200000  61186.0  61343.0  60852.0  61009.5  8.998808e+07   \n",
       "1   1635112800000  61009.5  61103.5  60860.0  60957.5  3.615479e+07   \n",
       "2   1635116400000  60957.5  60995.5  60752.0  60901.5  4.064861e+07   \n",
       "3   1635120000000  60901.5  61840.0  60708.5  61827.5  1.381452e+08   \n",
       "4   1635123600000  61827.5  62145.5  61730.0  61746.0  1.034869e+08   \n",
       "..            ...      ...      ...      ...      ...           ...   \n",
       "75  1635379200000  58481.5  58917.5  58305.0  58327.0  8.970379e+07   \n",
       "76  1635382800000  58327.0  59022.0  58144.0  58945.0  1.322635e+08   \n",
       "77  1635386400000  58945.0  58945.0  58720.0  58940.0  2.747237e+07   \n",
       "78  1635390000000  58940.0  59184.0  58739.0  58889.5  5.342441e+07   \n",
       "79  1635393600000  58889.5  59237.0  58872.0  58905.0  4.696608e+07   \n",
       "\n",
       "             timestamp  \n",
       "0  2021-10-24 21:00:00  \n",
       "1  2021-10-24 22:00:00  \n",
       "2  2021-10-24 23:00:00  \n",
       "3  2021-10-25 00:00:00  \n",
       "4  2021-10-25 01:00:00  \n",
       "..                 ...  \n",
       "75 2021-10-28 00:00:00  \n",
       "76 2021-10-28 01:00:00  \n",
       "77 2021-10-28 02:00:00  \n",
       "78 2021-10-28 03:00:00  \n",
       "79 2021-10-28 04:00:00  \n",
       "\n",
       "[80 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(bybit.fetch_ohlcv(\"BTCUSDT\", timeframe=\"1h\", limit=80))  \n",
    "test_dates = test[0] \n",
    "test_timestamps = [] \n",
    "for i in range(len(test_dates)): \n",
    "    date_string = bybit.iso8601(int(test_dates[i]))  \n",
    "    date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "    test_timestamps.append(date_string) \n",
    "    \n",
    "test['timestamp'] = test_timestamps \n",
    "test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [00:00<00:00, 5376.85it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 20 \n",
    "future_size = 1 \n",
    "test_enc_inputs = [] \n",
    "test_dec_inputs = [] \n",
    "test_targets = [] \n",
    "test_enc_marks = [] \n",
    "test_dec_marks = [] \n",
    "\n",
    "for i in tqdm(range(test.shape[0] - window_size - future_size), position=0, leave=True):  \n",
    "    ### get enc_inputs, dec_inputs and targets ### \n",
    "    o = test[1].values[i:i+window_size+future_size] \n",
    "    h = test[2].values[i:i+window_size+future_size] \n",
    "    l = test[3].values[i:i+window_size+future_size] \n",
    "    c = test[4].values[i:i+window_size+future_size] \n",
    "    v = test[5].values[i:i+window_size+future_size] \n",
    "    \n",
    "    o = (o - np.min(o)) / (np.max(o) - np.min(o)) \n",
    "    h = (h - np.min(h)) / (np.max(h) - np.min(h)) \n",
    "    l = (l - np.min(l)) / (np.max(l) - np.min(l)) \n",
    "    c = (c - np.min(c)) / (np.max(c) - np.min(c)) \n",
    "    v = v / np.max(v)  \n",
    "    \n",
    "    o_train = o[:window_size].reshape((-1,1)) \n",
    "    o_target = o[-1].reshape((-1,1)) \n",
    "    h_train = h[:window_size].reshape((-1,1))\n",
    "    h_target = h[-1].reshape((-1,1)) \n",
    "    l_train = l[:window_size].reshape((-1,1)) \n",
    "    l_target = l[-1].reshape((-1,1)) \n",
    "    c_train = c[:window_size].reshape((-1,1)) \n",
    "    c_target = c[-1].reshape((-1,1)) \n",
    "    v_train = v[:window_size].reshape((-1,1)) \n",
    "    v_target = v[-1].reshape((-1,1)) \n",
    "    \n",
    "    x = np.concatenate([o_train,h_train,l_train,c_train,v_train],axis=1) \n",
    "    y = np.concatenate([o_target,h_target,l_target,c_target,v_target],axis=1)\n",
    "    y0 = np.zeros((1,5)) \n",
    "\n",
    "    test_enc_inputs.append(x) \n",
    "    test_dec_inputs.append(np.concatenate([x,y0], axis = 0)) \n",
    "    test_targets.append(y)  \n",
    "    \n",
    "    month = df['month'].values[i:i+window_size+future_size].reshape((-1,1)) \n",
    "    day = df['day'].values[i:i+window_size+future_size].reshape((-1,1))\n",
    "    weekday = df['weekday'].values[i:i+window_size+future_size].reshape((-1,1))\n",
    "    hour = df['hour'].values[i:i+window_size+future_size].reshape((-1,1))\n",
    "        \n",
    "    enc_dates = np.concatenate([month[:-1,:], day[:-1,:], weekday[:-1,:], hour[:-1,:]], axis=1)  \n",
    "    test_enc_marks.append(enc_dates) \n",
    "    \n",
    "    dec_dates = np.concatenate([month, day, weekday, hour], axis=1) \n",
    "    test_dec_marks.append(dec_dates) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59, 20, 5), (59, 21, 5), (59, 1, 5), (59, 20, 4), (59, 21, 4))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_enc_inputs = np.array(test_enc_inputs) \n",
    "test_dec_inputs = np.array(test_dec_inputs) \n",
    "test_targets = np.array(test_targets) \n",
    "test_enc_marks = np.array(test_enc_marks) \n",
    "test_dec_marks = np.array(test_dec_marks) \n",
    "\n",
    "test_enc_inputs.shape, test_dec_inputs.shape, test_targets.shape, test_enc_marks.shape, test_dec_marks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss = 0.0363\n",
      "correct = 54/59\n",
      "accuracy = 91.5254%\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(test_enc_inputs, \n",
    "                             test_dec_inputs, \n",
    "                             test_targets, \n",
    "                             test_enc_marks,\n",
    "                             test_dec_marks) \n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = BATCH_SIZE, shuffle = False)  \n",
    "\n",
    "checkpoint = torch.load('btc_informer_stack_19_val_loss_0.014904952798546716') \n",
    "test_model = InformerStack(enc_in = 5, # encoder input size \n",
    "                           dec_in = 5, # decoder input size \n",
    "                           c_out = 5, # output size  \n",
    "                           seq_len = window_size, # encoder sequence length \n",
    "                           label_len = window_size, # starter token length \n",
    "                           out_len = future_size, # output sequence length \n",
    "                           attn = 'prob') # use probsparse attention  \n",
    "test_model.load_state_dict(checkpoint)\n",
    "test_model.cuda() \n",
    "test_model.eval() # change to eval mode \n",
    " \n",
    "test_loss = 0 \n",
    "correct = 0 \n",
    "total_cnt = 0 \n",
    "eps = 1e-10\n",
    "for batch in test_dataloader: \n",
    "    encoder_input = batch['encoder_input'].to(device) \n",
    "    decoder_input = batch['decoder_input'].to(device) \n",
    "    target = batch['target'].to(device) \n",
    "    enc_marks = batch['encoder_marks'].to(device)  \n",
    "    dec_marks = batch['decoder_marks'].to(device) \n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        outputs = test_model(x_enc=encoder_input,\n",
    "                            x_mark_enc=enc_marks, \n",
    "                            x_dec=decoder_input, \n",
    "                            x_mark_dec=dec_marks) \n",
    "        loss = criterion(outputs, target) \n",
    "        test_loss += loss.item()   \n",
    "        \n",
    "        pred_y = outputs.detach().cpu().numpy()[:,:,0] \n",
    "        actual_y = target.detach().cpu().numpy()[:,:,0] \n",
    "        previous_y = encoder_input.detach().cpu().numpy()[:,-1,0].reshape((-1,1))\n",
    "        \n",
    "        for i in range(len(pred_y)): \n",
    "            if pred_y[i] >= previous_y[i] and actual_y[i] >= previous_y[i]: \n",
    "                correct += 1 \n",
    "            elif pred_y[i] < previous_y[i] and actual_y[i] < previous_y[i]: \n",
    "                correct += 1 \n",
    "            total_cnt += 1  \n",
    "    \n",
    "    \n",
    "print(\"total loss = {:.4f}\".format(test_loss)) \n",
    "print(\"correct = {}/{}\".format(correct, total_cnt))  \n",
    "print(\"accuracy = {:.4f}%\".format(correct * 100 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
