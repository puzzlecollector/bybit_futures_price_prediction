{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "import random \n",
    "import os \n",
    "import torch \n",
    "from torch import nn  \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from sklearn.model_selection import train_test_split \n",
    "import time \n",
    "import datetime \n",
    "import json\n",
    "import ccxt \n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1585130400000</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>2.636600e+01</td>\n",
       "      <td>2020-03-25 10:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1585134000000</td>\n",
       "      <td>6591.5</td>\n",
       "      <td>6628.5</td>\n",
       "      <td>6457.5</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>2.857722e+06</td>\n",
       "      <td>2020-03-25 11:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1585137600000</td>\n",
       "      <td>6511.5</td>\n",
       "      <td>6588.5</td>\n",
       "      <td>6502.0</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>3.484765e+06</td>\n",
       "      <td>2020-03-25 12:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1585141200000</td>\n",
       "      <td>6583.5</td>\n",
       "      <td>6745.5</td>\n",
       "      <td>6562.0</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>2.957732e+06</td>\n",
       "      <td>2020-03-25 13:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1585144800000</td>\n",
       "      <td>6585.0</td>\n",
       "      <td>6640.0</td>\n",
       "      <td>6516.0</td>\n",
       "      <td>6590.0</td>\n",
       "      <td>1.705696e+06</td>\n",
       "      <td>2020-03-25 14:00:00</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0       1       2       3       4             5  \\\n",
       "0  1585130400000  6500.0  6591.5  6500.0  6591.5  2.636600e+01   \n",
       "1  1585134000000  6591.5  6628.5  6457.5  6511.5  2.857722e+06   \n",
       "2  1585137600000  6511.5  6588.5  6502.0  6583.5  3.484765e+06   \n",
       "3  1585141200000  6583.5  6745.5  6562.0  6585.0  2.957732e+06   \n",
       "4  1585144800000  6585.0  6640.0  6516.0  6590.0  1.705696e+06   \n",
       "\n",
       "            timestamp  year  month  day  weekday  hour  \n",
       "0 2020-03-25 10:00:00  2020      3   25        2    10  \n",
       "1 2020-03-25 11:00:00  2020      3   25        2    11  \n",
       "2 2020-03-25 12:00:00  2020      3   25        2    12  \n",
       "3 2020-03-25 13:00:00  2020      3   25        2    13  \n",
       "4 2020-03-25 14:00:00  2020      3   25        2    14  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('BTC_USDT-1h_bybit.json') as f: \n",
    "    df = json.load(f) \n",
    "    \n",
    "df = pd.DataFrame(df) \n",
    "dates = df[0].values \n",
    "\n",
    "bybit = ccxt.bybit() \n",
    "timestamp = [] \n",
    "for i in range(len(dates)): \n",
    "    date_string = bybit.iso8601(int(dates[i]))  \n",
    "    date_string = date_string[:10] + \" \" + date_string[11:-5] \n",
    "    timestamp.append(date_string) \n",
    "    \n",
    "df['timestamp'] = timestamp\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']) \n",
    "\n",
    "df['year'] = df['timestamp'].dt.year \n",
    "df['month'] = df['timestamp'].dt.month \n",
    "df['day'] = df['timestamp'].dt.day \n",
    "df['weekday'] = df['timestamp'].dt.weekday \n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BTCUSDT_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13854/13854 [00:02<00:00, 6404.88it/s]\n"
     ]
    }
   ],
   "source": [
    "window_size = 20 \n",
    "future_size = 1 \n",
    "enc_inputs = [] \n",
    "dec_inputs = [] \n",
    "targets = [] \n",
    "\n",
    "for i in tqdm(range(df.shape[0] - window_size - future_size), position=0, leave=True):  \n",
    "    ### get enc_inputs, dec_inputs and targets ### \n",
    "    o = df[1].values[i:i+window_size+future_size] \n",
    "    h = df[2].values[i:i+window_size+future_size] \n",
    "    l = df[3].values[i:i+window_size+future_size] \n",
    "    c = df[4].values[i:i+window_size+future_size] \n",
    "    v = df[5].values[i:i+window_size+future_size] \n",
    "    \n",
    "    o = (o - np.min(o)) / (np.max(o) - np.min(o)) \n",
    "    h = (h - np.min(h)) / (np.max(h) - np.min(h)) \n",
    "    l = (l - np.min(l)) / (np.max(l) - np.min(l)) \n",
    "    c = (c - np.min(c)) / (np.max(c) - np.min(c)) \n",
    "    v = v / np.max(v)  \n",
    "    \n",
    "    o_train = o[:window_size].reshape((-1,1)) \n",
    "    o_target = o[-1].reshape((-1,1)) \n",
    "    h_train = h[:window_size].reshape((-1,1))\n",
    "    h_target = h[-1].reshape((-1,1)) \n",
    "    l_train = l[:window_size].reshape((-1,1)) \n",
    "    l_target = l[-1].reshape((-1,1)) \n",
    "    c_train = c[:window_size].reshape((-1,1)) \n",
    "    c_target = c[-1].reshape((-1,1)) \n",
    "    v_train = v[:window_size].reshape((-1,1)) \n",
    "    v_target = v[-1].reshape((-1,1)) \n",
    "    \n",
    "    x = np.concatenate([o_train,h_train,l_train,c_train,v_train],axis=1) \n",
    "    y = np.concatenate([o_target,h_target,l_target,c_target,v_target],axis=1)\n",
    "    y0 = np.zeros([1, y.shape[1]]) # start of decoder inputs \n",
    "\n",
    "    enc_inputs.append(x) \n",
    "    dec_inputs.append(np.concatenate([y0, y], axis = 0)) \n",
    "    targets.append(y)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13854, 20, 5), (13854, 2, 5), (13854, 1, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inputs = np.array(enc_inputs)\n",
    "dec_inputs = np.array(dec_inputs)\n",
    "targets = np.array(targets) \n",
    "\n",
    "enc_inputs.shape, dec_inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "    def __init__(self, encoder_input, decoder_input): \n",
    "        self.encoder_input = encoder_input \n",
    "        self.decoder_input = decoder_input \n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.encoder_input) \n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        return {\n",
    "            'encoder_input': torch.tensor(self.encoder_input[i], dtype=torch.float32), \n",
    "            'decoder_input': torch.tensor(self.decoder_input[i], dtype=torch.float32), \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12468, 20, 5), (1386, 20, 5), (12468, 2, 5), (1386, 2, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(enc_inputs, dec_inputs, random_state = 888, test_size = 0.1)\n",
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "\n",
    "train_dataset = CustomDataset(x_train, y_train)\n",
    "\n",
    "val_dataset = CustomDataset(x_val, y_val) \n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True) \n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") # GPU 사용\n",
    "target_n = 5 # number of features\n",
    "learning_rate = 5e-4  \n",
    "BATCH_SIZE = 32  \n",
    "EPOCHS = 50 \n",
    "teacher_forcing = True  \n",
    "n_layers = 3 # number of GRU layers \n",
    "dropout = 0.2  \n",
    "window_size = 20 # encoder sequence length \n",
    "future_size = 1 # decoder sequence length \n",
    "hidden_dim = 128 # rnn hidden dimension \n",
    "save_path = f'btc_seq2seq.pt' # model save path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module): \n",
    "    def __init__(self, input_dim, hidden_dim, n_layers, dropout): \n",
    "        super().__init__() \n",
    "        self.n_layers = n_layers \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        \n",
    "    def forward(self, inp_seq): \n",
    "        inp_seq = inp_seq.permute(1,0,2) \n",
    "        outputs, hidden = self.rnn(inp_seq) \n",
    "        return outputs, hidden\n",
    "    \n",
    "class BahdanauAttention(nn.Module): \n",
    "    def __init__(self, dec_output_dim, units): \n",
    "        super(BahdanauAttention, self).__init__() \n",
    "        self.W1 = nn.Linear(dec_output_dim, units) \n",
    "        self.W2 = nn.Linear(dec_output_dim, units) \n",
    "        self.V = nn.Linear(dec_output_dim, 1) \n",
    "    \n",
    "    def forward(self, hidden, enc_output): \n",
    "        query_with_time_axis = hidden.unsqueeze(1) \n",
    "        score = self.V(torch.tanh(self.W1(query_with_time_axis) + self.W2(enc_output))) \n",
    "        attention_weights = torch.softmax(score, axis=1) \n",
    "        context_vector = attention_weights * enc_output \n",
    "        context_vector = torch.sum(context_vector, dim = 1) \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "class Decoder(nn.Module): \n",
    "    def __init__(self, dec_feature_size, encoder_hidden_dim, output_dim, decoder_hidden_dim, n_layers, dropout, attention):\n",
    "        super().__init__() \n",
    "        self.output_dim = output_dim \n",
    "        self.decoder_hidden_dim = decoder_hidden_dim \n",
    "        self.n_layers = n_layers \n",
    "        self.attention = attention \n",
    "        self.layer = nn.Linear(dec_feature_size, encoder_hidden_dim) \n",
    "        self.rnn = nn.GRU(encoder_hidden_dim*2, decoder_hidden_dim, n_layers, dropout=dropout) \n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim) \n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "    \n",
    "    def forward(self, enc_output, dec_input, hidden): \n",
    "        dec_input = self.layer(dec_input) \n",
    "        context_vector, attention_weight = self.attention(hidden, enc_output) \n",
    "        dec_input = torch.cat([torch.sum(context_vector, dim=0), dec_input], dim=1) \n",
    "        dec_input = dec_input.unsqueeze(0) \n",
    "        output, hidden = self.rnn(dec_input, hidden) \n",
    "        prediction = self.fc_out(output.sum(0)) \n",
    "        return prediction, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module): \n",
    "    def __init__(self, encoder, decoder, attention): \n",
    "        super().__init__() \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder \n",
    "    \n",
    "    def forward(self, encoder_input, decoder_input, teacher_forcing=False):\n",
    "        batch_size = decoder_input.size(0)\n",
    "        trg_len = decoder_input.size(1) \n",
    "        outputs = torch.zeros(batch_size, trg_len-1, self.decoder.output_dim).to(device) \n",
    "        enc_output, hidden = self.encoder(encoder_input) \n",
    "        dec_input = decoder_input[:,0] \n",
    "        for t in range(1, trg_len): \n",
    "            output, hidden = self.decoder(enc_output, dec_input, hidden) \n",
    "            outputs[:,t-1] = output\n",
    "            if teacher_forcing == True: \n",
    "                dec_input = decoder_input[:,t] \n",
    "            else: \n",
    "                dec_input = output \n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (rnn): GRU(5, 128, num_layers=3, dropout=0.2)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): BahdanauAttention(\n",
       "      (W1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (V): Linear(in_features=128, out_features=1, bias=True)\n",
       "    )\n",
       "    (layer): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (rnn): GRU(256, 128, num_layers=3, dropout=0.2)\n",
       "    (fc_out): Linear(in_features=128, out_features=5, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(input_dim = x_train.shape[-1], hidden_dim = hidden_dim, n_layers = n_layers, dropout=dropout) \n",
    "attention = BahdanauAttention(dec_output_dim=hidden_dim, units=hidden_dim) \n",
    "decoder = Decoder(\n",
    "    dec_feature_size = target_n, encoder_hidden_dim=hidden_dim, output_dim=target_n, \n",
    "    decoder_hidden_dim=hidden_dim, n_layers=n_layers, dropout=dropout, \n",
    "    attention=attention \n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, attention) \n",
    "model = model.cuda() \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.022511280328035354\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.021674601137638094\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.02150089164574941\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.020981292063370346\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.02086304534599185\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.020794773205804327\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0204787445454193\n",
      "\n",
      "  Average training loss: 0.020515684256903255\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.018599652494727212\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 2 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.019815205726772547\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.020114998361095787\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.020204267390072347\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.019873262215405703\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.019697719234973193\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.019603023985400796\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01959522937557527\n",
      "\n",
      "  Average training loss: 0.019500720866311053\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017878325338560073\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 3 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.0182743301987648\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.018621109602972866\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01856601985792319\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.018592943837866187\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01859233643487096\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01881168145686388\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01895871897095016\n",
      "\n",
      "  Average training loss: 0.018888415463077717\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.017475253140384502\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 4 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.019084320720285177\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.019057343313470483\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.018629663934310276\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.018493031430989505\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01804732771217823\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.018073712879170974\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.018095196006553512\n",
      "\n",
      "  Average training loss: 0.018126962450929943\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016737201579169116\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 5 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.017571308426558973\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.017458139625377952\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.017696706804757316\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.017803252118173987\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.017562161987647415\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01771656864322722\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.017687716204673052\n",
      "\n",
      "  Average training loss: 0.017521946397251808\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01701528352515941\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 6 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.016241805665194987\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01638353326357901\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01655434977884094\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.0168559488048777\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01687026157975197\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.016999193606898187\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.016967817874891416\n",
      "\n",
      "  Average training loss: 0.017080380079837944\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016683586640283465\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 7 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01701407043263316\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.016507421154528856\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.016557863525425393\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01673980475170538\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01656369781680405\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.016634204966636996\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0166601260711572\n",
      "\n",
      "  Average training loss: 0.016838332219049335\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01686129304157062\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 8 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01651475622318685\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.016750801680609585\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.017053411317368348\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.017006395794451238\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.016552234441041945\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01661943508932988\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01651517402646797\n",
      "\n",
      "  Average training loss: 0.016466660305666618\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016194585086354477\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 9 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.016325660375878216\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01626366688404232\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01648863029666245\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01621768986573443\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01618322362937033\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.016130410580274958\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.016191859813407063\n",
      "\n",
      "  Average training loss: 0.01624067731273289\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01609720329923386\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 10 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.016387909818440675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.016448071179911494\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.016282268936435383\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01657105950638652\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01661919583380222\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.016668726736679674\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.016448512175785645\n",
      "\n",
      "  Average training loss: 0.016403778659132045\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.016962580107660455\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 11 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.016483859699219464\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01674206961877644\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.016311309076845647\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01609484591986984\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.015934001591056585\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015943552078679205\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.016133020166307688\n",
      "\n",
      "  Average training loss: 0.016089747669414067\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015618592585352335\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 12 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.015173714132979512\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.015886686583980916\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01598404752711455\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.016127426819875838\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.016107368376106025\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.016073644269878666\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.015968315956581915\n",
      "\n",
      "  Average training loss: 0.015900596321966404\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01573587884195149\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 13 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01386055739596486\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01506656794808805\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.015788950969775516\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01585107995197177\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015683064952492713\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015671877418644727\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.015484025099181703\n",
      "\n",
      "  Average training loss: 0.01565071909258572\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01576991087164391\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 14 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.015449949372559786\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01537544619757682\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01558333027176559\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.015497574089094997\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.015574861284345388\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015413680461545785\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.015517665319410817\n",
      "\n",
      "  Average training loss: 0.015552200126246763\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01642339037392627\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 15 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.015276775574311613\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.015149834253825246\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.015545834961036842\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.015179688318166882\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015269917776808143\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015348647958599032\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.015344634912908077\n",
      "\n",
      "  Average training loss: 0.015447147879510736\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.015684925855814734\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 16 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01480674521997571\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.014378073927946388\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.015215508897478382\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01522489363560453\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015519133621826768\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015587986235817274\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.015488297436386347\n",
      "\n",
      "  Average training loss: 0.015384752594698698\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014919970925389365\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 17 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.015298605570569635\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.014467753856442868\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.014615373046447833\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.015022761728614569\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.015152513952925802\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.015232389342660706\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.015170511820220521\n",
      "\n",
      "  Average training loss: 0.015175149162323811\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014902500276961788\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 18 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01407619183883071\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01443270624615252\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.014395401167372862\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.014636299719568343\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01498913630656898\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.014982492124351363\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.015045961868017911\n",
      "\n",
      "  Average training loss: 0.014950732729182794\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014718275051563978\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 19 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.014950966257601976\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.014572001160122455\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01486045436002314\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.014808843904174864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.014722200311720371\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01468475386655579\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.014742293384458337\n",
      "\n",
      "  Average training loss: 0.01492845216431679\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01555468266914514\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 20 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.014320888062939048\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.014591908203437925\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.014485624749213458\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01465169038856402\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.014681410796940327\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.014601498305176696\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.014624252168993865\n",
      "\n",
      "  Average training loss: 0.014625411151120296\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01464855237017301\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 21 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01483515890315175\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01464775977190584\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.014740035847450296\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.0145127905998379\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.014465769911184907\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.014382559795243045\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01426394199553345\n",
      "\n",
      "  Average training loss: 0.014420551161926526\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014623377673243258\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 22 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.014371836371719838\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.014631141950376332\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.014237071620300412\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.014372814293019474\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01449002667888999\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.0143600355166321\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.01439505093464894\n",
      "\n",
      "  Average training loss: 0.014341923027323225\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014348079958422617\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 23 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01333270825445652\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.014006671272218227\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.013794903264691433\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.014030749925877899\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01404498186148703\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.014167463003347317\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.013891388003581336\n",
      "\n",
      "  Average training loss: 0.013955619545557942\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014319103592160072\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 24 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.013380301501601934\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01353449625428766\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.013567885433634122\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.013594043760094791\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.013739255987107754\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.013751444903512796\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.013761285309280669\n",
      "\n",
      "  Average training loss: 0.013881844394386578\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014076196228746663\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 25 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.013755974536761641\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.013427031892351806\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.013293226255724827\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.013405968635343015\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.013371785372495651\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01343861171665291\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.013557586804298418\n",
      "\n",
      "  Average training loss: 0.013586298404977873\n",
      "  Training epoch took: 0:00:08\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014046788776547393\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 26 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01331138776615262\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.013413797938264907\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01322342977548639\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.013187245880253613\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.013216950736939907\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.013450305320632955\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.013451110047421284\n",
      "\n",
      "  Average training loss: 0.013510647621483374\n",
      "  Training epoch took: 0:00:08\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013818098369731822\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 27 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.013136680526658893\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.012834756337106228\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.012834293954074382\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.012907636833842844\n",
      "  Batch   250  of    390.    Elapsed: 0:00:09.\n",
      "  current average loss = 0.012966255869716406\n",
      "  Batch   300  of    390.    Elapsed: 0:00:10.\n",
      "  current average loss = 0.01312040532939136\n",
      "  Batch   350  of    390.    Elapsed: 0:00:11.\n",
      "  current average loss = 0.013123854851084096\n",
      "\n",
      "  Average training loss: 0.013187919762463142\n",
      "  Training epoch took: 0:00:12\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.0134677777426656\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 28 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.012873012982308864\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01239323799032718\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.012578727702299754\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.013144770998042076\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.013067822406068444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.013078952527915438\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.013137614652514458\n",
      "\n",
      "  Average training loss: 0.013111354605270884\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013592949327589436\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 29 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011275946851819754\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.012124391058459878\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.012243074715758364\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.012600341027136893\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.012876399556174874\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.012746006998543937\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01273391803726554\n",
      "\n",
      "  Average training loss: 0.0128935024393006\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013648376778953454\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 30 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.013003634475171565\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.012551269088871777\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01263077116260926\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01247306632809341\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.012422559686005115\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.012484668539837002\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.012575187994433301\n",
      "\n",
      "  Average training loss: 0.01260195793225788\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013500461989844387\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 31 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.012784685753285886\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.012703099865466356\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01284407804099222\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.012682762390468269\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.012635495703667402\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.0125488193348671\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.012571479792573623\n",
      "\n",
      "  Average training loss: 0.012503704103903893\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013579685071652586\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 32 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01147316986694932\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.012039804765954613\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011899154962350925\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011987989828921854\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.012139624988660216\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.012274856772273779\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01228374898034547\n",
      "\n",
      "  Average training loss: 0.01228226708749739\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013280716714110564\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 33 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011941986652091145\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01188704474363476\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011915370707089703\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011821518570650369\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.012048053588718176\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.012016418632119894\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.012071116480178067\n",
      "\n",
      "  Average training loss: 0.012064507260966377\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013866521386345003\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 34 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011755379205569625\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.011958661107346415\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.012346377888073523\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01229601765749976\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.012189169455319643\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.012119661627026896\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.012159328018980366\n",
      "\n",
      "  Average training loss: 0.012002810797630213\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013208275724371726\n",
      "  Validation epoch took: 0:00:00\n",
      "Saving Best Checkpoint....\n",
      "\n",
      "======== Epoch 35 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011072045974433422\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.011016505495645106\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011079824802776177\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011081508062779903\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011145116435363889\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011336630255294343\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.011510036143341234\n",
      "\n",
      "  Average training loss: 0.011697481135622812\n",
      "  Training epoch took: 0:00:08\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013247950171882456\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 36 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011527536297217011\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.011314933043904603\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01103213001973927\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011405118275433779\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011588818157091736\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011632117368280888\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011539478618651629\n",
      "\n",
      "  Average training loss: 0.011548906383224023\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013277485691518947\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 37 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011244629388675093\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.011318845194764435\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011356421047821641\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011481611272320152\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011562487460672856\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011499512740410864\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011442513805148857\n",
      "\n",
      "  Average training loss: 0.011465286802596007\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013478361863896927\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 38 / 50 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.01080065525136888\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.011148237730376423\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011264759721234441\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.011234771539457143\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.011230841783806681\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01112517926686754\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011120981486248118\n",
      "\n",
      "  Average training loss: 0.011223424120973317\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013542738266881894\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 39 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.011103529687970877\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.010645187394693494\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01075623966443042\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.010920833228155971\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01088689780049026\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.011029394306242467\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.011094902536964843\n",
      "\n",
      "  Average training loss: 0.011117007473531441\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013690150893208656\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 40 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.009704404408112169\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.010113269221037627\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.01033870857829849\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.010414030323736369\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01072674978338182\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.010830178333756824\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.010870981807155268\n",
      "\n",
      "  Average training loss: 0.010976176891619196\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013371606494977394\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 41 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.010192542830482125\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.01026485559064895\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.010225139524166782\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.010360703906044363\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01053030507452786\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.01064340100158006\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.01072098145660545\n",
      "\n",
      "  Average training loss: 0.010753843520218746\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013447558285075833\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 42 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.010411789920181037\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.010613877805881203\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.010457980794211228\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01043636882212013\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.01033290258795023\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.010303082720686993\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.010405631087986486\n",
      "\n",
      "  Average training loss: 0.010420655067532491\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01343059886924245\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 43 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.009618750121444464\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.010403625071048736\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.010353658696015676\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.010344851224217563\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.010267455410212279\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.010321445766215524\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.010398498766922525\n",
      "\n",
      "  Average training loss: 0.010300356392056132\n",
      "  Training epoch took: 0:00:08\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013599308863790198\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 44 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.009878520155325532\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.00989170695655048\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.010115177677944303\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.009903580450918525\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.00988234381750226\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.00993466740474105\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.01006247012609882\n",
      "\n",
      "  Average training loss: 0.010067521823713413\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013504399473524907\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 45 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.009368142522871494\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.009702206109650433\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.00970409844070673\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.009706962730269879\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.00975017828680575\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009878250163358946\n",
      "  Batch   350  of    390.    Elapsed: 0:00:07.\n",
      "  current average loss = 0.009919331278651952\n",
      "\n",
      "  Average training loss: 0.009974044519595993\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.01437083084601909\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 46 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.00948468029499054\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.009700359739363194\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.009861403920998177\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.009692156030796468\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.009586344223469496\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.009641487762952844\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009720863508326667\n",
      "\n",
      "  Average training loss: 0.00974987386725843\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014322107499042018\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 47 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.008776279259473085\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.009076929246075451\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.009233375247567892\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.00930396769195795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.009475310981273652\n",
      "  Batch   300  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009379148807687063\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009542875345796347\n",
      "\n",
      "  Average training loss: 0.009552275012127864\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013726661585017362\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 48 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.008819781262427568\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.009053702326491475\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.009152800412848591\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.009103793017566204\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.009087019486352802\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.009234243690346679\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009311893993456449\n",
      "\n",
      "  Average training loss: 0.009345342125743627\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014373057786459949\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 49 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.008441537832841278\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.008509945939294994\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.008852783891682824\n",
      "  Batch   200  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.008959375713020563\n",
      "  Batch   250  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.008967429967597126\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.008891996433958412\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.009005586496953454\n",
      "\n",
      "  Average training loss: 0.009071528419661216\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.013960339848629454\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "======== Epoch 50 / 50 ========\n",
      "Training...\n",
      "  Batch    50  of    390.    Elapsed: 0:00:01.\n",
      "  current average loss = 0.00806867347098887\n",
      "  Batch   100  of    390.    Elapsed: 0:00:02.\n",
      "  current average loss = 0.008300602775998414\n",
      "  Batch   150  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.008505580133448045\n",
      "  Batch   200  of    390.    Elapsed: 0:00:03.\n",
      "  current average loss = 0.008770488726440817\n",
      "  Batch   250  of    390.    Elapsed: 0:00:04.\n",
      "  current average loss = 0.008921961251646281\n",
      "  Batch   300  of    390.    Elapsed: 0:00:05.\n",
      "  current average loss = 0.008927106099824111\n",
      "  Batch   350  of    390.    Elapsed: 0:00:06.\n",
      "  current average loss = 0.008843641162716917\n",
      "\n",
      "  Average training loss: 0.008836967745222725\n",
      "  Training epoch took: 0:00:07\n",
      "\n",
      "Running Validation...\n",
      "\n",
      "  Average validation loss: 0.014055903905748644\n",
      "  Validation epoch took: 0:00:00\n",
      "\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "model.zero_grad() \n",
    "\n",
    "# for reproducibility \n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "train_losses, val_losses = [], [] \n",
    "\n",
    "for epoch_i in range(0, EPOCHS): \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n",
    "    print('Training...')\n",
    "    t0 = time.time() \n",
    "    total_loss = 0 \n",
    "    model.train() \n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):  \n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "            print('  current average loss = {}'.format(total_loss / step))\n",
    "            \n",
    "        encoder_input = batch['encoder_input'].to(device) \n",
    "        decoder_input = batch['decoder_input'].to(device) \n",
    "        \n",
    "        with torch.cuda.amp.autocast(): \n",
    "            output = model(encoder_input, decoder_input, teacher_forcing) \n",
    "            loss = criterion(output, decoder_input[:,1:])\n",
    "            total_loss += loss.item() \n",
    "            loss.backward() \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step() \n",
    "            # gradient initialization \n",
    "            model.zero_grad() \n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)  \n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time() \n",
    "    model.eval() \n",
    "    eval_loss = 0 \n",
    "    for batch in val_dataloader: \n",
    "        encoder_input = batch['encoder_input'].to(device) \n",
    "        decoder_input = batch['decoder_input'].to(device) \n",
    "                \n",
    "        with torch.no_grad(): \n",
    "            outputs = model(encoder_input, decoder_input, False) \n",
    "            loss = criterion(outputs, decoder_input[:,1:]) \n",
    "            eval_loss += loss.item()  \n",
    "        \n",
    "    avg_val_loss = eval_loss / len(val_dataloader) \n",
    "    val_losses.append(avg_val_loss) \n",
    "    print(\"\")\n",
    "    print(\"  Average validation loss: {}\".format(avg_val_loss))\n",
    "    print(\"  Validation epoch took: {:}\".format(format_time(time.time() - t0))) \n",
    "        \n",
    "    if np.min(val_losses) == val_losses[-1]: \n",
    "        print(\"Saving Best Checkpoint....\")\n",
    "        torch.save(model.state_dict(), \"btc_seq2seq_\" + str(epoch_i + 1) + \"_val_loss_\" + str(val_losses[-1])) \n",
    "\n",
    "        \n",
    "        \n",
    "print(\"\")\n",
    "print(\"Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='train_loss') \n",
    "plt.plot(val_losses, label='val_loss') \n",
    "plt.xlabel('epoch') \n",
    "plt.ylabel('loss(mse)') \n",
    "plt.title('loss_plot') \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1635109200000</td>\n",
       "      <td>61186.0</td>\n",
       "      <td>61343.0</td>\n",
       "      <td>60852.0</td>\n",
       "      <td>61009.5</td>\n",
       "      <td>8.998808e+07</td>\n",
       "      <td>2021-10-24 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1635112800000</td>\n",
       "      <td>61009.5</td>\n",
       "      <td>61103.5</td>\n",
       "      <td>60860.0</td>\n",
       "      <td>60957.5</td>\n",
       "      <td>3.615479e+07</td>\n",
       "      <td>2021-10-24 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1635116400000</td>\n",
       "      <td>60957.5</td>\n",
       "      <td>60995.5</td>\n",
       "      <td>60752.0</td>\n",
       "      <td>60901.5</td>\n",
       "      <td>4.064861e+07</td>\n",
       "      <td>2021-10-24 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1635120000000</td>\n",
       "      <td>60901.5</td>\n",
       "      <td>61840.0</td>\n",
       "      <td>60708.5</td>\n",
       "      <td>61827.5</td>\n",
       "      <td>1.381452e+08</td>\n",
       "      <td>2021-10-25 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1635123600000</td>\n",
       "      <td>61827.5</td>\n",
       "      <td>62145.5</td>\n",
       "      <td>61730.0</td>\n",
       "      <td>61746.0</td>\n",
       "      <td>1.034869e+08</td>\n",
       "      <td>2021-10-25 01:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1        2        3        4             5  \\\n",
       "0  1635109200000  61186.0  61343.0  60852.0  61009.5  8.998808e+07   \n",
       "1  1635112800000  61009.5  61103.5  60860.0  60957.5  3.615479e+07   \n",
       "2  1635116400000  60957.5  60995.5  60752.0  60901.5  4.064861e+07   \n",
       "3  1635120000000  60901.5  61840.0  60708.5  61827.5  1.381452e+08   \n",
       "4  1635123600000  61827.5  62145.5  61730.0  61746.0  1.034869e+08   \n",
       "\n",
       "             timestamp  \n",
       "0  2021-10-24 21:00:00  \n",
       "1  2021-10-24 22:00:00  \n",
       "2  2021-10-24 23:00:00  \n",
       "3  2021-10-25 00:00:00  \n",
       "4  2021-10-25 01:00:00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_data.csv\") \n",
    "test.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:00<00:00, 2121.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((59, 20, 5), (59, 2, 5), (59, 1, 5))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size = 20 \n",
    "future_size = 1 \n",
    "test_enc_inputs = [] \n",
    "test_dec_inputs = [] \n",
    "test_targets = [] \n",
    "\n",
    "for i in tqdm(range(test.shape[0] - window_size - future_size), position=0, leave=True):  \n",
    "    ### get enc_inputs, dec_inputs and targets ### \n",
    "    o = test.iloc[:,1].values[i:i+window_size+future_size] \n",
    "    h = test.iloc[:,2].values[i:i+window_size+future_size] \n",
    "    l = test.iloc[:,3].values[i:i+window_size+future_size] \n",
    "    c = test.iloc[:,4].values[i:i+window_size+future_size] \n",
    "    v = test.iloc[:,5].values[i:i+window_size+future_size] \n",
    "    \n",
    "    o = (o - np.min(o)) / (np.max(o) - np.min(o)) \n",
    "    h = (h - np.min(h)) / (np.max(h) - np.min(h)) \n",
    "    l = (l - np.min(l)) / (np.max(l) - np.min(l)) \n",
    "    c = (c - np.min(c)) / (np.max(c) - np.min(c)) \n",
    "    v = v / np.max(v)  \n",
    "    \n",
    "    o_train = o[:window_size].reshape((-1,1)) \n",
    "    o_target = o[-1].reshape((-1,1)) \n",
    "    h_train = h[:window_size].reshape((-1,1))\n",
    "    h_target = h[-1].reshape((-1,1)) \n",
    "    l_train = l[:window_size].reshape((-1,1)) \n",
    "    l_target = l[-1].reshape((-1,1)) \n",
    "    c_train = c[:window_size].reshape((-1,1)) \n",
    "    c_target = c[-1].reshape((-1,1)) \n",
    "    v_train = v[:window_size].reshape((-1,1)) \n",
    "    v_target = v[-1].reshape((-1,1)) \n",
    "    \n",
    "    x = np.concatenate([o_train,h_train,l_train,c_train,v_train],axis=1) \n",
    "    y = np.concatenate([o_target,h_target,l_target,c_target,v_target],axis=1)\n",
    "    \n",
    "    test_enc_inputs.append(x) \n",
    "    test_dec_inputs.append(np.zeros([future_size+1,target_n])) \n",
    "    test_targets.append(y)\n",
    "    \n",
    "test_enc_inputs = np.array(test_enc_inputs) \n",
    "test_dec_inputs = np.array(test_dec_inputs)  \n",
    "test_targets = np.array(test_targets)\n",
    "\n",
    "test_enc_inputs.shape, test_dec_inputs.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss = 0.7768\n",
      "correct = 53/59\n",
      "accuracy = 89.8305%\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('btc_seq2seq_34_val_loss_0.013208275724371726') \n",
    "test_model = Seq2Seq(encoder, decoder, attention)  \n",
    "test_model.load_state_dict(checkpoint) \n",
    "test_model.cuda() \n",
    "test_model.eval() # change to eval mode \n",
    "\n",
    "test_loss = 0 \n",
    "correct = 0 \n",
    "total_cnt = 0 \n",
    "eps = 1e-10\n",
    "for i in range(len(test_enc_inputs)): \n",
    "    encoder_input = torch.tensor(test_enc_inputs[i], dtype=torch.float32).to(device) \n",
    "    decoder_input = torch.tensor(test_dec_inputs[i], dtype=torch.float32).to(device) \n",
    "    test_target = torch.tensor(test_targets[i], dtype=torch.float32).to(device)  \n",
    "    \n",
    "    encoder_input = torch.reshape(encoder_input, (1,20,5)) \n",
    "    decoder_input = torch.reshape(decoder_input, (1,2,5)) \n",
    "    test_target = torch.reshape(test_target, (1,1,5)) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = test_model(encoder_input, decoder_input, False)\n",
    "        loss = criterion(outputs, test_target)\n",
    "        test_loss += loss.item() \n",
    "        pred_y = outputs.detach().cpu().numpy()[:,:,0]\n",
    "        previous_y = encoder_input.detach().cpu().numpy()[:,-1,0].reshape((-1,1)) \n",
    "        actual_y = test_target.detach().cpu().numpy()[:,:,0]\n",
    "        \n",
    "        for i in range(len(pred_y)): \n",
    "            if pred_y[i] >= previous_y[i] and actual_y[i] >= previous_y[i]: \n",
    "                correct += 1 \n",
    "            elif pred_y[i] < previous_y[i] and actual_y[i] < previous_y[i]: \n",
    "                correct += 1 \n",
    "            total_cnt += 1  \n",
    "            \n",
    "\n",
    "print(\"total loss = {:.4f}\".format(test_loss)) \n",
    "print(\"correct = {}/{}\".format(correct, total_cnt))  \n",
    "print(\"accuracy = {:.4f}%\".format(correct * 100 / total_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
